{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.insert(0, '../')\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from gantools import data\n",
    "from gantools import utils\n",
    "from gantools import plot\n",
    "from gantools.model import WGAN, CosmoWGAN\n",
    "from gantools.gansystem import GANsystem\n",
    "from gantools.data import fmap\n",
    "from gantools import evaluation\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = 64 # Resolution of the image\n",
    "try_resume = True # Try to resume previous simulation\n",
    "Mpch = 350 # Type of dataset (select 70 or 350)\n",
    "\n",
    "\n",
    "forward = fmap.stat_forward\n",
    "backward = fmap.stat_backward\n",
    "def non_lin(x):\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.load.load_nbody_dataset(nsamples=None, spix=ns, Mpch=Mpch, forward_map=forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset can return an iterator.\n",
    "it = dataset.iter(10)\n",
    "print(next(it).shape)\n",
    "del it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the data\n",
    "X = dataset.get_all_data().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the backward maps invert the forward map.\n",
    "assert(np.sum(np.abs(forward(backward(X))-X))< 5)\n",
    "# # For debugging\n",
    "# np.sum(np.abs(forward(backward(X))-X))\n",
    "# forward(backward(X))-X\n",
    "# x = np.arange(1e4)\n",
    "# plt.plot(x, backward(forward(x))-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the histogram of the pixel densities after the forward map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X, 100)\n",
    "print('min: {}'.format(np.min(X)))\n",
    "print('max: {}'.format(np.max(X)))\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to free some memory\n",
    "del X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot 16 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plot.draw_images(dataset.get_samples(N=16),nx=4,ny=4);\n",
    "plt.title(\"Real samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters for the WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_str = '2D'\n",
    "\n",
    "global_path = 'saved_results'\n",
    "\n",
    "name = 'WGAN{}'.format(ns) + '_' + time_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = False\n",
    "\n",
    "md=64\n",
    "\n",
    "params_discriminator = dict()\n",
    "params_discriminator['stride'] = [1, 2, 2, 2, 2]\n",
    "params_discriminator['nfilter'] = [md, md, 2*md, 4*md, 8*md]\n",
    "params_discriminator['shape'] = [[5, 5],[5, 5],[5, 5], [5, 5], [5, 5]]\n",
    "params_discriminator['batch_norm'] = [bn, bn, bn, bn, bn ]\n",
    "params_discriminator['full'] = []\n",
    "params_discriminator['minibatch_reg'] = False\n",
    "params_discriminator['summary'] = True\n",
    "params_discriminator['data_size'] = 2\n",
    "params_discriminator['inception'] = False\n",
    "params_discriminator['spectral_norm'] = True\n",
    "\n",
    "params_generator = dict()\n",
    "params_generator['stride'] = [2, 2, 2, 2, 1]\n",
    "params_generator['latent_dim'] = 100\n",
    "params_generator['in_conv_shape'] =[4,4]\n",
    "params_generator['nfilter'] = [4*md, 2*md, md, md, 1]\n",
    "params_generator['shape'] = [[5, 5],[5, 5], [5, 5],[5, 5],[5, 5]]\n",
    "params_generator['batch_norm'] = [bn, bn, bn,bn ]\n",
    "params_generator['full'] = [4*4*4*md]\n",
    "params_generator['summary'] = True\n",
    "params_generator['non_lin'] = None\n",
    "params_generator['data_size'] = 2\n",
    "params_generator['inception'] = False\n",
    "params_generator['spectral_norm'] = True\n",
    "\n",
    "# Optimization parameters inspired from 'Self-Attention Generative Adversarial Networks'\n",
    "# - Spectral normalization GEN DISC\n",
    "# - Batch norm GEN\n",
    "# - TTUR ('GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium')\n",
    "# - ADAM  beta1=0 beta2=0.9, disc lr 0.0004, gen lr 0.0001\n",
    "# - Hinge loss\n",
    "# Parameters are similar to the ones in those papers...\n",
    "# - 'PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION'\n",
    "# - 'LARGE SCALE GAN TRAINING FOR HIGH FIDELITY NATURAL IMAGE SYNTHESIS'\n",
    "# - 'CGANS WITH PROJECTION DISCRIMINATOR'\n",
    "\n",
    "params_optimization = dict()\n",
    "params_optimization['batch_size'] = 32\n",
    "params_optimization['epoch'] = 100\n",
    "params_optimization['n_critic'] = 5\n",
    "# params_optimization['generator'] = dict()\n",
    "# params_optimization['generator']['optimizer'] = 'adam'\n",
    "# params_optimization['generator']['kwargs'] = {'beta1':0, 'beta2':0.9}\n",
    "# params_optimization['generator']['learning_rate'] = 0.0004\n",
    "# params_optimization['discriminator'] = dict()\n",
    "# params_optimization['discriminator']['optimizer'] = 'adam'\n",
    "# params_optimization['discriminator']['kwargs'] = {'beta1':0, 'beta2':0.9}\n",
    "# params_optimization['discriminator']['learning_rate'] = 0.0001\n",
    "\n",
    "# Cosmology parameters\n",
    "params_cosmology = dict()\n",
    "params_cosmology['forward_map'] = forward\n",
    "params_cosmology['backward_map'] = backward\n",
    "\n",
    "\n",
    "# all parameters\n",
    "params = dict()\n",
    "params['net'] = dict() # All the parameters for the model\n",
    "params['net']['generator'] = params_generator\n",
    "params['net']['discriminator'] = params_discriminator\n",
    "params['net']['cosmology'] = params_cosmology # Parameters for the cosmological summaries\n",
    "params['net']['prior_distribution'] = 'gaussian'\n",
    "params['net']['shape'] = [ns, ns, 1] # Shape of the image\n",
    "params['net']['loss'] = 'wasserstein' # loss ('hinge' or 'wasserstein')\n",
    "params['net']['gamma_gp'] = 10 # Gradient penalty\n",
    "params['net']['upsampling'] = None \n",
    "\n",
    "params['optimization'] = params_optimization\n",
    "params['summary_every'] = 100 # Tensorboard summaries every ** iterations\n",
    "params['print_every'] = 50 # Console summaries every ** iterations\n",
    "params['save_every'] = 1000 # Save the model every ** iterations\n",
    "params['summary_dir'] = os.path.join(global_path, name +'_summary/')\n",
    "params['save_dir'] = os.path.join(global_path, name + '_checkpoints/')\n",
    "params['Nstats'] = 2000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume, params = utils.test_resume(try_resume, params)\n",
    "# If a model is reloaded and some parameters have to be changed, then it should be done here.\n",
    "# For example, setting the number of epoch to 5 would be:\n",
    "params['optimization']['epoch'] = 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan = GANsystem(CosmoWGAN, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan.train(dataset, resume=resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate new samples\n",
    "To have meaningful statistics, be sure to generate enough samples\n",
    "* 2000 : 32 x 32\n",
    "* 500 : 64 x 64\n",
    "* 200 : 128 x 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2000 # Number of samples\n",
    "gen_sample = np.squeeze(wgan.generate(N=N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a few fake samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plot.draw_images(gen_sample,nx=4,ny=4);\n",
    "plt.title(\"Fake samples\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the sample quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before computing the statistics, we need to invert the mapping\n",
    "raw_images = backward(dataset.get_samples(dataset.N))\n",
    "gen_sample_raw = backward(gen_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logel2, l2, logel1, l1 = evaluation.compute_and_plot_psd(raw_images, gen_sample_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logel2, l2, logel1, l1 = evaluation.compute_and_plot_peak_cout(raw_images, gen_sample_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logel2, l2, logel1, l1 = evaluation.compute_and_plot_mass_hist(raw_images, gen_sample_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
