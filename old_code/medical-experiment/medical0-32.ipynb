{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, functools\n",
    "from gantools import data, utils\n",
    "from gantools.model import WGAN\n",
    "from gantools.gansystem import GANsystem\n",
    "from gantools import blocks\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume, the training will start from the last iteration!\n"
     ]
    }
   ],
   "source": [
    "ns = 32\n",
    "try_resume = True\n",
    "latent_dim = 100\n",
    "\n",
    "time_str = '0_to_32' \n",
    "global_path = '../saved_result/medical/'\n",
    "name = 'WGAN_'+time_str\n",
    "\n",
    "def non_lin(x):\n",
    "    return (tf.nn.tanh(x) + 1.0)/2.0\n",
    "\n",
    "bn = False\n",
    "\n",
    "md = 32\n",
    "\n",
    "params_discriminator = dict()\n",
    "params_discriminator['stride'] = [2, 1, 1, 1, 1, 1]\n",
    "params_discriminator['nfilter'] = [md, md*8, md*8, md, 8, 2]\n",
    "params_discriminator['inception'] = True\n",
    "params_discriminator['batch_norm'] = [bn, bn, bn, bn, bn, bn]\n",
    "params_discriminator['full'] = []\n",
    "params_discriminator['summary'] = True\n",
    "params_discriminator['minibatch_reg'] = True\n",
    "params_discriminator['data_size'] = 3\n",
    "\n",
    "params_generator = dict()\n",
    "params_generator['stride'] = [1, 2, 2, 2, 1, 1, 1, 1]\n",
    "params_generator['latent_dim'] = latent_dim\n",
    "params_generator['nfilter'] = [8, md*64, md*8, md, md, md, md, 1]\n",
    "params_generator['inception'] = True\n",
    "params_generator['batch_norm'] = [bn, bn, bn, bn, bn, bn, bn]\n",
    "params_generator['full'] = [4*4*4*8]\n",
    "params_generator['summary'] = True\n",
    "params_generator['non_lin'] = non_lin\n",
    "params_generator['data_size'] = 3\n",
    "params_generator['in_conv_shape'] = [4, 4, 4]\n",
    "# params_generator['activation'] = blocks.selu\n",
    "\n",
    "params_optimization = dict()\n",
    "params_optimization['n_critic'] = 10\n",
    "params_optimization['batch_size'] = 8\n",
    "params_optimization['epoch'] = 10000\n",
    "\n",
    "\n",
    "params = dict()\n",
    "params['net'] = dict()\n",
    "params['net']['shape'] = [ns, ns, ns, 1]\n",
    "params['net']['generator'] = params_generator\n",
    "params['net']['gamma'] = 10\n",
    "params['net']['discriminator'] = params_discriminator\n",
    "\n",
    "params['optimization'] = params_optimization\n",
    "params['summary_every'] = 100 # Tensorboard summaries every ** iterations\n",
    "params['print_every'] = 50 # Console summaries every ** iterations\n",
    "params['save_every'] = 1000 # Save the model every ** iterations\n",
    "params['summary_dir'] = os.path.join(global_path, name +'_summary/')\n",
    "params['save_dir'] = os.path.join(global_path, name + '_checkpoints/')\n",
    "params['Nstats'] = 10\n",
    "\n",
    "\n",
    "resume, params = utils.test_resume(try_resume, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator \n",
      "--------------------------------------------------\n",
      "     The input is of size (?, 100)\n",
      "     0 Full layer with 512 outputs\n",
      "         Size of the variables: (?, 512)\n",
      "     Reshape to (?, 4, 4, 4, 8)\n",
      "     0 Inception deconv(1x1,3x3,5x5) layer with 8 channels\n",
      "         Non linearity applied\n",
      "         Size of the variables: (?, 4, 4, 4, 24)\n",
      "     1 Inception deconv(1x1,3x3,5x5) layer with 2048 channels\n",
      "         Non linearity applied\n",
      "         Size of the variables: (?, 8, 8, 8, 6144)\n",
      "     2 Inception deconv(1x1,3x3,5x5) layer with 256 channels\n",
      "         Non linearity applied\n",
      "         Size of the variables: (?, 16, 16, 16, 768)\n",
      "     3 Inception deconv(1x1,3x3,5x5) layer with 32 channels\n",
      "         Non linearity applied\n",
      "         Size of the variables: (?, 32, 32, 32, 96)\n",
      "     4 Inception deconv(1x1,3x3,5x5) layer with 32 channels\n",
      "         Non linearity applied\n",
      "         Size of the variables: (?, 32, 32, 32, 96)\n",
      "     5 Inception deconv(1x1,3x3,5x5) layer with 32 channels\n",
      "         Non linearity applied\n",
      "         Size of the variables: (?, 32, 32, 32, 96)\n",
      "     6 Inception deconv(1x1,3x3,5x5) layer with 32 channels\n",
      "         Non linearity applied\n",
      "         Size of the variables: (?, 32, 32, 32, 96)\n",
      "     7 Inception deconv(1x1,3x3,5x5) layer with 1 channels\n",
      "         Size of the variables: (?, 32, 32, 32, 1)\n",
      "    Costum non linearity: <function non_lin at 0x7f0be683ed90>\n",
      "     The output is of size (?, 32, 32, 32, 1)\n",
      "--------------------------------------------------\n",
      "\n",
      "Discriminator \n",
      "--------------------------------------------------\n",
      "     The input is of size (?, 32, 32, 32, 1)\n",
      "     0 Inception(1x1,3x3,5x5) layer with 32 channels\n",
      "         Size of the variables: (?, 16, 16, 16, 96)\n",
      "     1 Inception(1x1,3x3,5x5) layer with 256 channels\n",
      "         Size of the variables: (?, 16, 16, 16, 768)\n",
      "     2 Inception(1x1,3x3,5x5) layer with 256 channels\n",
      "         Size of the variables: (?, 16, 16, 16, 768)\n",
      "     3 Inception(1x1,3x3,5x5) layer with 32 channels\n",
      "         Size of the variables: (?, 16, 16, 16, 96)\n",
      "     4 Inception(1x1,3x3,5x5) layer with 8 channels\n",
      "         Size of the variables: (?, 16, 16, 16, 24)\n",
      "     5 Inception(1x1,3x3,5x5) layer with 2 channels\n",
      "         Size of the variables: (?, 16, 16, 16, 2)\n",
      "     Reshape to (?, 8192)\n",
      "     6 Full layer with 1 outputs\n",
      "     The output is of size (?, 1)\n",
      "--------------------------------------------------\n",
      "\n",
      " Using gradients clipping\n",
      "Add summary for descriptives/mean_real\n",
      "Add summary for descriptives/var_real\n",
      "Add summary for descriptives/min_real\n",
      "Add summary for descriptives/max_real\n",
      "Add summary for descriptives/kurtosis_real\n",
      "Add summary for descriptives/skewness_real\n",
      "Add summary for descriptives/median_real\n",
      "Add summary for descriptives/mean_fake\n",
      "Add summary for descriptives/var_fake\n",
      "Add summary for descriptives/min_fake\n",
      "Add summary for descriptives/max_fake\n",
      "Add summary for descriptives/kurtosis_fake\n",
      "Add summary for descriptives/skewness_fake\n",
      "Add summary for descriptives/median_fake\n",
      "Add summary for descriptives/mean_l2\n",
      "Add summary for descriptives/var_l2\n",
      "Add summary for descriptives/min_l2\n",
      "Add summary for descriptives/max_l2\n",
      "Add summary for descriptives/kurtosis_l2\n",
      "Add summary for descriptives/skewness_l2\n",
      "Add summary for descriptives/median_l2\n",
      "Add summary for final/mass_histogram_l2\n",
      "Add summary for final/peak_histogram_l2\n",
      "Add summary for final/psd_l2log\n",
      "Add summary for final/global_score\n",
      "Add summary for wasserstein/mass_histogram_l2\n",
      "Add summary for wasserstein/psd_l2\n",
      "Add summary for wasserstein/global_score\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "generator/0_full/Matrix:0 (float32_ref 100x512) [51200, bytes: 204800]\n",
      "generator/0_full/bias:0 (float32_ref 512) [512, bytes: 2048]\n",
      "generator/0_deconv_1_by_1/w:0 (float32_ref 1x1x1x8x8) [64, bytes: 256]\n",
      "generator/0_deconv_1_by_1/biases:0 (float32_ref 8) [8, bytes: 32]\n",
      "generator/0_deconv_3_by_3/w:0 (float32_ref 3x3x3x8x8) [1728, bytes: 6912]\n",
      "generator/0_deconv_3_by_3/biases:0 (float32_ref 8) [8, bytes: 32]\n",
      "generator/0_deconv_5_by_5/w:0 (float32_ref 5x5x5x8x8) [8000, bytes: 32000]\n",
      "generator/0_deconv_5_by_5/biases:0 (float32_ref 8) [8, bytes: 32]\n",
      "generator/1_deconv_1_by_1/w:0 (float32_ref 1x1x1x2048x24) [49152, bytes: 196608]\n",
      "generator/1_deconv_1_by_1/biases:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "generator/1_deconv_3_by_3/w:0 (float32_ref 3x3x3x2048x24) [1327104, bytes: 5308416]\n",
      "generator/1_deconv_3_by_3/biases:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "generator/1_deconv_5_by_5/w:0 (float32_ref 5x5x5x2048x24) [6144000, bytes: 24576000]\n",
      "generator/1_deconv_5_by_5/biases:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "generator/2_deconv_1_by_1/w:0 (float32_ref 1x1x1x256x6144) [1572864, bytes: 6291456]\n",
      "generator/2_deconv_1_by_1/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
      "generator/2_deconv_3_by_3/w:0 (float32_ref 3x3x3x256x6144) [42467328, bytes: 169869312]\n",
      "generator/2_deconv_3_by_3/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
      "generator/2_deconv_5_by_5/w:0 (float32_ref 5x5x5x256x6144) [196608000, bytes: 786432000]\n",
      "generator/2_deconv_5_by_5/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
      "generator/3_deconv_1_by_1/w:0 (float32_ref 1x1x1x32x768) [24576, bytes: 98304]\n",
      "generator/3_deconv_1_by_1/biases:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/3_deconv_3_by_3/w:0 (float32_ref 3x3x3x32x768) [663552, bytes: 2654208]\n",
      "generator/3_deconv_3_by_3/biases:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/3_deconv_5_by_5/w:0 (float32_ref 5x5x5x32x768) [3072000, bytes: 12288000]\n",
      "generator/3_deconv_5_by_5/biases:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/4_deconv_1_by_1/w:0 (float32_ref 1x1x1x32x96) [3072, bytes: 12288]\n",
      "generator/4_deconv_1_by_1/biases:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/4_deconv_3_by_3/w:0 (float32_ref 3x3x3x32x96) [82944, bytes: 331776]\n",
      "generator/4_deconv_3_by_3/biases:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/4_deconv_5_by_5/w:0 (float32_ref 5x5x5x32x96) [384000, bytes: 1536000]\n",
      "generator/4_deconv_5_by_5/biases:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/5_deconv_1_by_1/w:0 (float32_ref 1x1x1x32x96) [3072, bytes: 12288]\n",
      "generator/5_deconv_1_by_1/biases:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/5_deconv_3_by_3/w:0 (float32_ref 3x3x3x32x96) [82944, bytes: 331776]\n",
      "generator/5_deconv_3_by_3/biases:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/5_deconv_5_by_5/w:0 (float32_ref 5x5x5x32x96) [384000, bytes: 1536000]\n",
      "generator/5_deconv_5_by_5/biases:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/6_deconv_1_by_1/w:0 (float32_ref 1x1x1x32x96) [3072, bytes: 12288]\n",
      "generator/6_deconv_1_by_1/biases:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/6_deconv_3_by_3/w:0 (float32_ref 3x3x3x32x96) [82944, bytes: 331776]\n",
      "generator/6_deconv_3_by_3/biases:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/6_deconv_5_by_5/w:0 (float32_ref 5x5x5x32x96) [384000, bytes: 1536000]\n",
      "generator/6_deconv_5_by_5/biases:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/7_deconv_1_by_1/w:0 (float32_ref 1x1x1x1x96) [96, bytes: 384]\n",
      "generator/7_deconv_1_by_1/biases:0 (float32_ref 1) [1, bytes: 4]\n",
      "generator/7_deconv_3_by_3/w:0 (float32_ref 3x3x3x1x96) [2592, bytes: 10368]\n",
      "generator/7_deconv_3_by_3/biases:0 (float32_ref 1) [1, bytes: 4]\n",
      "generator/7_deconv_5_by_5/w:0 (float32_ref 5x5x5x1x96) [12000, bytes: 48000]\n",
      "generator/7_deconv_5_by_5/biases:0 (float32_ref 1) [1, bytes: 4]\n",
      "generator/7_deconv_1_by_1_merge/w:0 (float32_ref 1x1x1x1x3) [3, bytes: 12]\n",
      "generator/7_deconv_1_by_1_merge/biases:0 (float32_ref 1) [1, bytes: 4]\n",
      "discriminator/0_conv_1_by_1/w:0 (float32_ref 1x1x1x1x32) [32, bytes: 128]\n",
      "discriminator/0_conv_1_by_1/biases:0 (float32_ref 32) [32, bytes: 128]\n",
      "discriminator/0_conv_3_by_3/w:0 (float32_ref 3x3x3x1x32) [864, bytes: 3456]\n",
      "discriminator/0_conv_3_by_3/biases:0 (float32_ref 32) [32, bytes: 128]\n",
      "discriminator/0_conv_5_by_5/w:0 (float32_ref 5x5x5x1x32) [4000, bytes: 16000]\n",
      "discriminator/0_conv_5_by_5/biases:0 (float32_ref 32) [32, bytes: 128]\n",
      "discriminator/1_conv_1_by_1/w:0 (float32_ref 1x1x1x96x256) [24576, bytes: 98304]\n",
      "discriminator/1_conv_1_by_1/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/1_conv_3_by_3/w:0 (float32_ref 3x3x3x96x256) [663552, bytes: 2654208]\n",
      "discriminator/1_conv_3_by_3/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/1_conv_5_by_5/w:0 (float32_ref 5x5x5x96x256) [3072000, bytes: 12288000]\n",
      "discriminator/1_conv_5_by_5/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/2_conv_1_by_1/w:0 (float32_ref 1x1x1x768x256) [196608, bytes: 786432]\n",
      "discriminator/2_conv_1_by_1/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/2_conv_3_by_3/w:0 (float32_ref 3x3x3x768x256) [5308416, bytes: 21233664]\n",
      "discriminator/2_conv_3_by_3/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/2_conv_5_by_5/w:0 (float32_ref 5x5x5x768x256) [24576000, bytes: 98304000]\n",
      "discriminator/2_conv_5_by_5/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/3_conv_1_by_1/w:0 (float32_ref 1x1x1x768x32) [24576, bytes: 98304]\n",
      "discriminator/3_conv_1_by_1/biases:0 (float32_ref 32) [32, bytes: 128]\n",
      "discriminator/3_conv_3_by_3/w:0 (float32_ref 3x3x3x768x32) [663552, bytes: 2654208]\n",
      "discriminator/3_conv_3_by_3/biases:0 (float32_ref 32) [32, bytes: 128]\n",
      "discriminator/3_conv_5_by_5/w:0 (float32_ref 5x5x5x768x32) [3072000, bytes: 12288000]\n",
      "discriminator/3_conv_5_by_5/biases:0 (float32_ref 32) [32, bytes: 128]\n",
      "discriminator/4_conv_1_by_1/w:0 (float32_ref 1x1x1x96x8) [768, bytes: 3072]\n",
      "discriminator/4_conv_1_by_1/biases:0 (float32_ref 8) [8, bytes: 32]\n",
      "discriminator/4_conv_3_by_3/w:0 (float32_ref 3x3x3x96x8) [20736, bytes: 82944]\n",
      "discriminator/4_conv_3_by_3/biases:0 (float32_ref 8) [8, bytes: 32]\n",
      "discriminator/4_conv_5_by_5/w:0 (float32_ref 5x5x5x96x8) [96000, bytes: 384000]\n",
      "discriminator/4_conv_5_by_5/biases:0 (float32_ref 8) [8, bytes: 32]\n",
      "discriminator/5_conv_1_by_1/w:0 (float32_ref 1x1x1x24x2) [48, bytes: 192]\n",
      "discriminator/5_conv_1_by_1/biases:0 (float32_ref 2) [2, bytes: 8]\n",
      "discriminator/5_conv_3_by_3/w:0 (float32_ref 3x3x3x24x2) [1296, bytes: 5184]\n",
      "discriminator/5_conv_3_by_3/biases:0 (float32_ref 2) [2, bytes: 8]\n",
      "discriminator/5_conv_5_by_5/w:0 (float32_ref 5x5x5x24x2) [6000, bytes: 24000]\n",
      "discriminator/5_conv_5_by_5/biases:0 (float32_ref 2) [2, bytes: 8]\n",
      "discriminator/5_conv_1_by_1_merge/w:0 (float32_ref 1x1x1x6x2) [12, bytes: 48]\n",
      "discriminator/5_conv_1_by_1_merge/biases:0 (float32_ref 2) [2, bytes: 8]\n",
      "discriminator/minibatch_reg/Matrix:0 (float32_ref 8192x4500) [36864000, bytes: 147456000]\n",
      "discriminator/minibatch_reg/bias:0 (float32_ref 4500) [4500, bytes: 18000]\n",
      "discriminator/out/Matrix:0 (float32_ref 8342x1) [8342, bytes: 33368]\n",
      "discriminator/out/bias:0 (float32_ref 1) [1, bytes: 4]\n",
      "Total size of variables: 328031782\n",
      "Total bytes of variables: 1312127128\n"
     ]
    }
   ],
   "source": [
    "wgan = GANsystem(WGAN, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.load.load_medical_dataset(spix=ns, scaling=8, patch=False, augmentation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute real statistics: descriptives/mean_l2\n",
      "Compute real statistics: descriptives/var_l2\n",
      "Compute real statistics: descriptives/min_l2\n",
      "Compute real statistics: descriptives/max_l2\n",
      "Compute real statistics: descriptives/kurtosis_l2\n",
      "Compute real statistics: descriptives/skewness_l2\n",
      "Compute real statistics: descriptives/median_l2\n",
      "Compute real statistics: final/mass_histogram_l2\n",
      "Compute real statistics: final/peak_histogram_l2\n",
      "Compute real statistics: final/psd_l2log\n",
      "Compute real statistics: wasserstein/mass_histogram_l2\n",
      "Compute real statistics: wasserstein/psd_l2\n",
      "Load weights in the network\n",
      " [*] Reading checkpoints...\n",
      "INFO:tensorflow:Restoring parameters from ../saved_result/medical/WGAN_0_to_32_checkpoints/wgan-2\n",
      "Start training\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "wgan.train(dataset, resume=resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
