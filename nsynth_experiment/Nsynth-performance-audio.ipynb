{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.insert(0, '../')\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from gantools import evaluation\n",
    "from gantools import data\n",
    "from gantools import utils\n",
    "from gantools import plot\n",
    "from gantools.model import WGAN, LapWGAN\n",
    "from gantools.gansystem import GANsystem\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from gantools import blocks\n",
    "\n",
    "from scipy.io import wavfile\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# this is a wrapper that take a filename and publish an html <audio> tag to listen to it\n",
    "\n",
    "def wavPlayer(filepath):\n",
    "    \"\"\" will display html 5 player for compatible browser\n",
    "\n",
    "    Parameters :\n",
    "    ------------\n",
    "    filepath : relative filepath with respect to the notebook directory ( where the .ipynb are not cwd)\n",
    "               of the file to play\n",
    "\n",
    "    The browser need to know how to play wav through html5.\n",
    "\n",
    "    there is no autoplay to prevent file playing when the browser opens\n",
    "    \"\"\"\n",
    "    \n",
    "    src = \"\"\"\n",
    "    <head>\n",
    "    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
    "    <title>Simple Test</title>\n",
    "    </head>\n",
    "    \n",
    "    <body>\n",
    "    <audio controls=\"controls\" style=\"width:600px\" >\n",
    "      <source src=\"files/%s\" type=\"audio/wav\" />\n",
    "      Your browser does not support the audio element.\n",
    "    </audio>\n",
    "    </body>\n",
    "    \"\"\"%(filepath)\n",
    "    display(HTML(src))\n",
    "\n",
    "def play_sound(x, fs, filename=None):\n",
    "    if filename is None:\n",
    "        filename = str(np.random.randint(10000))+'.wav'\n",
    "    wavfile.write(filename, np.int(fs), (x*(2**15)).astype(np.int16))\n",
    "    wavPlayer(filename)\n",
    "\n",
    "\n",
    "def load_gan(savepath, system=GANsystem,model=WGAN):\n",
    "    import gantools\n",
    "    pathparams = os.path.join(savepath, 'params.pkl')\n",
    "    with open(pathparams, 'rb') as f:          \n",
    "        params = params = pickle.load(f)\n",
    "    params['save_dir'] = savepath\n",
    "    return system(model, params)\n",
    "\n",
    "def plot_signals(sigs,\n",
    "                nx=1,\n",
    "                ny=1,\n",
    "                *args,\n",
    "                **kwargs):\n",
    "    \"\"\"\n",
    "    Draw multiple images. This function conveniently draw multiple images side\n",
    "    by side.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigs : List of Signales\n",
    "        - Matrix [ n , sx ]\n",
    "    \"\"\"\n",
    "    ndim = len(sigs.shape)\n",
    "    nimg = sigs.shape[0]\n",
    "\n",
    "    if ndim == 1:\n",
    "        raise ValueError('The input seems to contain only one signal')\n",
    "    elif ndim == 2:\n",
    "        if nx*ny>nimg:\n",
    "            raise ValueError(\"Not enough signals\")\n",
    "    else:\n",
    "        raise ValueError('The input contains to many dimensions')\n",
    "\n",
    "    f, ax = plt.subplots(ny, nx, sharey=True, figsize=(4*nx,3*ny))\n",
    "    it = 0\n",
    "    lim = np.max(np.abs(sigs))\n",
    "    xlim = (-lim, lim) \n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            if nx==1 or ny==1:\n",
    "                ax[j+i].plot(sigs[it])\n",
    "                ax[j+i].set_ylim(xlim)                \n",
    "            else:\n",
    "                ax[j,i].plot(sigs[it])\n",
    "                ax[j,i].set_ylim(xlim)\n",
    "            it += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalpath = '../saved_results/nsynth/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalings = 4**np.arange(4,-1,-1)\n",
    "fs = 16000/scalings\n",
    "nsamples = 2**15//scalings\n",
    "Nsamples = 100\n",
    "samples = [None]*len(scalings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.load.load_nsynth_dataset()\n",
    "sample_real_final = dataset.get_samples(100)\n",
    "samples_real = []\n",
    "for scaling in scalings:\n",
    "    samples_real.append(blocks.np_downsample_1d(sample_real_final, scaling))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate all new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n in range(len(scalings)):\n",
    "    savepath = os.path.join(globalpath, 'WGAN_nsynth_{}_checkpoints'.format(nsamples[n]))\n",
    "    if n==0:\n",
    "        obj = load_gan(savepath, model=WGAN)\n",
    "        samples[n] = obj.generate(N=Nsamples)\n",
    "    else:\n",
    "        obj = load_gan(savepath, model=LapWGAN)\n",
    "        samples[n] = obj.generate(X_down=samples[n-1])\n",
    "samples = [np.squeeze(sample) for sample in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for scaling, sample in zip(scalings,samples):\n",
    "    plot_signals(sample[:],nx=4,ny=1)\n",
    "    plt.suptitle('Fake, scaling {}'.format(scaling))\n",
    "    \n",
    "for scaling, sample in zip(scalings,samples_real):\n",
    "    plot_signals(sample[:],nx=4,ny=1)\n",
    "    plt.suptitle('Real, scaling {}'.format(scaling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_select = 14\n",
    "for n, scaling in enumerate(scalings):\n",
    "    print('Downsampling {}'.format(scaling))\n",
    "    cfs = fs[n]\n",
    "    sig = samples[n][n_select]\n",
    "    x=np.arange(len(sig))/cfs\n",
    "    plt.figure(figsize=(7,3))\n",
    "    plt.plot(x,sig)\n",
    "    play_sound(sig, cfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_select = 14\n",
    "for n, scaling in enumerate(scalings):\n",
    "    print('Downsampling {}'.format(scaling))\n",
    "    cfs = fs[n]\n",
    "    sig = samples_real[n][n_select]\n",
    "    x=np.arange(len(sig))/cfs\n",
    "    plt.figure(figsize=(7,3))\n",
    "    plt.plot(x,sig)\n",
    "    play_sound(sig, cfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by step evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_step = [None]*len(scalings)\n",
    "for n in range(len(scalings)):\n",
    "    savepath = os.path.join(globalpath, 'WGAN_nsynth_{}_checkpoints'.format(nsamples[n]))\n",
    "    if n==0:\n",
    "        samples_step[n] = samples_real[n]\n",
    "    else:\n",
    "        obj = load_gan(savepath, model=LapWGAN)\n",
    "        X_down = samples_real[n-1]\n",
    "        samples_step[n] = obj.generate(X_down=np.reshape(X_down, [*X_down.shape[:2],1]))\n",
    "samples_step = [np.squeeze(sample) for sample in samples_step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for scaling, fake, real in zip(scalings,samples_step, samples_real):\n",
    "    plot_signals(fake[:],nx=4,ny=1)\n",
    "    plt.suptitle('Fake, scaling {}'.format(scaling))\n",
    "    plot_signals(real[:],nx=4,ny=1)\n",
    "    plt.suptitle('Real, scaling {}'.format(scaling))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_select = 14\n",
    "for n, scaling in enumerate(scalings):\n",
    "    cfs = fs[n]\n",
    "    sig = samples_step[n][n_select]\n",
    "    x=np.arange(len(sig))/cfs\n",
    "    print('Downsampling {} - fake'.format(scaling))\n",
    "    play_sound(sig, cfs)\n",
    "    print('Downsampling {} - real'.format(scaling))\n",
    "    play_sound(samples_real[n][n_select], cfs)\n",
    "    \n",
    "    plt.figure(figsize=(7,3))\n",
    "    plt.plot(x,sig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
