{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='6'><b> Plots for the journal paper </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from moviepy.editor import VideoClip\n",
    "from moviepy.video.io.bindings import mplfig_to_npimage\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "# sys.path.insert(0, '../gantools/')\n",
    "# sys.path.insert(0, '../../tfnntools//')\n",
    "\n",
    "from gantools import utils\n",
    "from gantools import plot\n",
    "from gantools.gansystem import GANsystem\n",
    "from gantools.data import Dataset, Dataset_parameters\n",
    "from gantools.data import transformation\n",
    "\n",
    "from cosmotools.model import CosmoWGAN\n",
    "from cosmotools.metric import evaluation\n",
    "from cosmotools.data import load\n",
    "from cosmotools.utils import histogram_large, write_pickle, read_pickle, printt\n",
    "\n",
    "from gantools.model import ConditionalParamWGAN\n",
    "from gantools.gansystem import GANsystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ns = 128 # Resolution of the image\n",
    "try_resume = True # Try to resume previous simulation\n",
    "\n",
    "def non_lin(x):\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset_train_shuffled_name = 'kids_train_shuffled.h5'\n",
    "dataset_train_name = 'kids_train.h5'\n",
    "dataset_test_name = 'kids_test.h5'\n",
    "dataset_all_name = 'kids.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define parameters for the WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "time_str = '2D'\n",
    "global_path = '../saved_results/Kids/'\n",
    "name = 'KidsConditional{}'.format(ns) + '_smart_' + time_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn = False\n",
    "\n",
    "params_discriminator = dict()\n",
    "params_discriminator['stride'] = [1, 2, 2, 2, 2]\n",
    "params_discriminator['nfilter'] = [32, 64, 128, 256, 512]\n",
    "params_discriminator['shape'] = [[7, 7], [5, 5], [5, 5], [5,5], [3,3]]\n",
    "params_discriminator['batch_norm'] = [bn, bn, bn, bn, bn]\n",
    "params_discriminator['full'] = [512, 256, 128]\n",
    "params_discriminator['minibatch_reg'] = False\n",
    "params_discriminator['summary'] = True\n",
    "params_discriminator['data_size'] = 2\n",
    "\n",
    "params_generator = dict()\n",
    "params_generator['stride'] = [2, 2, 2, 2, 1]\n",
    "params_generator['latent_dim'] = 64\n",
    "params_generator['nfilter'] = [256, 128, 64, 32, 1]\n",
    "params_generator['shape'] = [[3, 3], [5, 5], [5, 5], [5, 5], [7,7]]\n",
    "params_generator['batch_norm'] = [bn, bn, bn, bn]\n",
    "params_generator['full'] = [256, 512, 8 * 8 * 512]\n",
    "params_generator['summary'] = True\n",
    "params_generator['non_lin'] = non_lin\n",
    "params_generator['data_size'] = 2\n",
    "\n",
    "params_optimization = dict()\n",
    "params_optimization['optimizer'] = 'rmsprop'\n",
    "params_optimization['batch_size'] = 64\n",
    "params_optimization['learning_rate'] = 1e-5\n",
    "params_optimization['epoch'] = 10\n",
    "\n",
    "# all parameters\n",
    "params = dict()\n",
    "params['net'] = dict() # All the parameters for the model\n",
    "params['net']['generator'] = params_generator\n",
    "params['net']['discriminator'] = params_discriminator\n",
    "params['net']['shape'] = [ns, ns, 1] # Shape of the image\n",
    "params['net']['gamma_gp'] = 10 # Gradient penalty\n",
    "\n",
    "# Conditional params\n",
    "params['net']['prior_normalization'] = False\n",
    "params['net']['cond_params'] = 2\n",
    "params['net']['init_range'] = [[0.101, 0.487], [0.487, 1.331]]\n",
    "params['net']['prior_distribution'] = \"gaussian_length\"\n",
    "params['net']['final_range'] = [0.1*np.sqrt(params_generator['latent_dim']), 1*np.sqrt(params_generator['latent_dim'])]\n",
    "\n",
    "params['optimization'] = params_optimization\n",
    "params['optimization']['discriminator'] = deepcopy(params_optimization)\n",
    "params['optimization']['generator'] = deepcopy(params_optimization)\n",
    "params['summary_every'] = 5000 # Tensorboard summaries every ** iterations\n",
    "params['print_every'] = 2500 # Console summaries every ** iterations\n",
    "params['save_every'] = 25000 # Save the model every ** iterations\n",
    "params['duality_every'] = 5\n",
    "params['summary_dir'] = os.path.join(global_path, name +'_summary/')\n",
    "params['save_dir'] = os.path.join(global_path, name + '_checkpoints/')\n",
    "params['Nstats'] = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "resume, params = utils.test_resume(try_resume, params)\n",
    "# If a model is reloaded and some parameters have to be changed, then it should be done here.\n",
    "# For example, setting the number of epoch to 5 would be:\n",
    "# params['optimization']['epoch'] = 5\n",
    "params['summary_dir'] = os.path.join(global_path, name +'_summary/')\n",
    "params['save_dir'] = os.path.join(global_path, name + '_checkpoints/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class CosmoConditionalParamWGAN(ConditionalParamWGAN, CosmoWGAN):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wgan = GANsystem(CosmoConditionalParamWGAN, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Download the checkpoint using the script `download_kids_checkpoint.py`.\n",
    "# Alternatively, you can train the model using:\n",
    "# dataset = load.load_params_dataset(filename=dataset_train_shuffled_name, batch=64, sorted=False, shape=[ns, ns])\n",
    "# wgan.train(dataset, resume=resume)\n",
    "# Training the model may erease the downloaded checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "checkpoint = 349163"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# FIGURE n-body vs GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Compare real and fake\n",
    "grid = np.array([[0.137, 1.23], [0.199, 0.87], [0.311, 0.842], [0.487, 0.643]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = load.load_params_dataset(filename=dataset_test_name, batch=10, sorted=True, shape=[ns, ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Produce images\n",
    "latent = wgan.net.sample_latent(bs=len(grid), params=grid)\n",
    "gen_images = wgan.generate(N=len(grid), **{'z': latent}, checkpoint=checkpoint)\n",
    "\n",
    "# Get real images\n",
    "real_images = []\n",
    "for p in grid:\n",
    "    real_images.append(dataset.get_data_for_params(p, N=10)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nrows, ncols=2, 4\n",
    "fontsize_title=20\n",
    "fontsize_label=20\n",
    "vmin=0.01\n",
    "vmax=0.12\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols*4, nrows*4))\n",
    "idx = 0\n",
    "kwargs_imshow = {'interpolation':'none'}\n",
    "for i in range(ncols):\n",
    "        plot.plot_img(real_images[i][np.random.randint(10)], vmin=vmin, vmax=vmax, ax=ax[0,i], kwargs_imshow=kwargs_imshow)\n",
    "        plot.plot_img(gen_images[i], vmin=vmin, vmax=vmax, ax=ax[1,i], kwargs_imshow=kwargs_imshow)\n",
    "for i in range(ncols):\n",
    "    title_str = r'$\\Omega_m={:2.2f} \\ \\ \\sigma_8={:2.2f}$'.format(grid[i][0], grid[i][1])\n",
    "    ax[0,i].set_title(title_str, fontsize=fontsize_title)\n",
    "ax[0,0].set_ylabel('N-body', fontsize=fontsize_label)\n",
    "ax[1,0].set_ylabel('GAN', fontsize=fontsize_label)\n",
    "fig.subplots_adjust(hspace=0.05, wspace=0.0)\n",
    "fig.savefig('figure_maps_nbody_vs_gan.pdf', bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# FIGURE latent interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inter = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Generate grid\n",
    "grid = []\n",
    "for c in range(wgan.net.params['cond_params']):\n",
    "    if c == 0:\n",
    "        gen_params = np.linspace(0.2, 0.4, inter)\n",
    "    if c == 1:\n",
    "        gen_params = np.linspace(0.70, 0.9, inter)\n",
    "    grid.append(gen_params)\n",
    "\n",
    "# Note: assume 2D grid of parameters\n",
    "gen_params = []\n",
    "for i in range(inter):\n",
    "    for j in range(inter):\n",
    "        gen_params.append([grid[0][i], grid[1][j]])\n",
    "gen_params = np.array(gen_params)\n",
    "\n",
    "imgs = evaluation.generate_samples_same_seed(wgan, gen_params, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dict_latent_interp = dict(imgs=imgs, gen_params=gen_params)\n",
    "write_pickle('latent_interpolation_images.pkl', dict_latent_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=inter, ncols=inter, figsize=(inter*4,inter*4), gridspec_kw={'hspace':0.05, 'wspace':0.01})\n",
    "idx = 0\n",
    "\n",
    "for i in range(inter):\n",
    "    for j in range(inter):\n",
    "        plot.plot_img(imgs[idx][0], vmin=0.01, vmax=0.12, ax=ax[i,j])\n",
    "        if i==0:\n",
    "            title_str = r'$\\sigma_8={:2.2f}$'.format(gen_params[idx][1])\n",
    "            ax[i,j].set_title(title_str, fontsize=fontsize_title)\n",
    "        if j==0:\n",
    "            title_str = r'$\\Omega_m={:2.2f}$'.format(gen_params[idx][0])\n",
    "            ax[i,j].set_ylabel(title_str, fontsize=fontsize_title)\n",
    "        \n",
    "        idx = idx + 1\n",
    "fig.savefig('figure_latent_interpolation.pdf', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate summary statistics (produces pickled results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate stats for the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load.load_params_dataset(filename=dataset_train_name, batch=N, sorted=True, shape=[ns, ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_train = dataset.get_different_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define getter functions for every parameter set\n",
    "# Note this is needed to save memory, as in this way every subset is loaded only when needed\n",
    "real_imgs = []\n",
    "fake_imgs = []\n",
    "for p in params_train:\n",
    "    real_imgs.append(lambda p1=p: dataset.get_data_for_params(p1, N=N)[0])\n",
    "    fake_imgs.append(lambda p1=p: evaluation.generate_samples_params(wgan, p1, nsamples=N, checkpoint=checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters used for plotting\n",
    "lenstools = True\n",
    "def title_func(params):\n",
    "    return \"$\\Omega_M$: \" + str(params[0])[0:7] + \", $\\sigma_8$: \" + str(params[1])[0:7]\n",
    "\n",
    "ylims = [[(1e-7, 1e-3), (0, 0.5)], \n",
    "         [(1e-2, 1e3), (0, 0.5)], \n",
    "         [(1e-2, 1e5), (0, 0.5)],\n",
    "         [(1e-7, 1e-3), (0, 0.5)],\n",
    "         [(1e-7, 1e-3), (0, 0.5)],\n",
    "         [(1e-7, 1e-3), (0, 0.5)]]\n",
    "    \n",
    "fractional_difference = [True]*6\n",
    "\n",
    "box_l = (5*np.pi/180)\n",
    "bin_k = 200\n",
    "cut = [200, 6000]\n",
    "cut_corr = [0, 6000]\n",
    "thresholds_minkowski = np.linspace(0.01, 0.1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, score_train, list_plotdata_stats  = evaluation.compute_plots_for_params(params_train, real_imgs, fake_imgs, param_str=title_func, ylims=ylims, log=False, confidence='std', lim=(0, 0.4), fractional_difference=fractional_difference, cut=cut, lenstools=lenstools, box_l=box_l, bin_k=bin_k, thresholds_minkowski=thresholds_minkowski)\n",
    "write_pickle('compute_plots_for_params__trainset.pkl', list_plotdata_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate 1D distribution tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load.load_params_dataset(filename=dataset_train_name, batch=N, sorted=True, shape=[ns, ns])\n",
    "params_train = dataset.get_different_params()\n",
    "real_imgs = []\n",
    "fake_imgs = []\n",
    "for p in params_train:\n",
    "    real_imgs.append(lambda p1=p: dataset.get_data_for_params(p1, N=N)[0])\n",
    "    fake_imgs.append(lambda p1=p: evaluation.generate_samples_params(wgan, p1, nsamples=N, checkpoint=checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wass_pixel, wass_peaks = evaluation.get_1D_sample_tests(params_train, real_imgs, fake_imgs)\n",
    "do = dict(wass_pixel=wass_pixel, wass_peaks=wass_peaks, params=params_train)\n",
    "write_pickle('mass_1D_tests__trainset.pkl', do)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate stats on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load.load_params_dataset(filename=dataset_test_name, batch=N, sorted=True, shape=[ns, ns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_inter = [[0.137, 1.23],\n",
    "                [0.25, 0.658],\n",
    "                [0.311, 0.842],\n",
    "                [0.199, 0.87],\n",
    "                [0.254, 0.852],\n",
    "                [0.312, 0.664],\n",
    "                [0.356, 0.614],\n",
    "                [0.421, 0.628]]\n",
    "\n",
    "\n",
    "params_inter = np.array(params_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define getter functions for every parameter set\n",
    "# Note this is needed to save memory, as in this way every subset is loaded only when needed\n",
    "real_imgs = []\n",
    "fake_imgs = []\n",
    "for p in params_inter:\n",
    "    real_imgs.append(lambda p1=p: dataset.get_data_for_params(p1, N=N)[0])\n",
    "    fake_imgs.append(lambda p1=p: evaluation.generate_samples_params(wgan, p1, nsamples=N, checkpoint=checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, score_inter, list_plotdata_stats = evaluation.compute_plots_for_params(params_inter, real_imgs, fake_imgs, param_str=title_func, ylims=ylims, log=False, confidence='std', lim=(0, 0.4), fractional_difference=fractional_difference, lenstools=lenstools, cut=cut, box_l=box_l, bin_k=bin_k, thresholds_minkowski=thresholds_minkowski)\n",
    "plt.close(fig)\n",
    "write_pickle('compute_plots_for_params__interpolation.pkl', list_plotdata_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pickle('compute_plots_for_params__interpolation.pkl', list_plotdata_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrapolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_extra = [[0.196, 1.225],\n",
    "                [0.127, 0.836],\n",
    "                [0.487, 0.643]]\n",
    "params_extra = np.array(params_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define getter functions for every parameter set\n",
    "# Note this is needed to save memory, as in this way every subset is loaded only when needed\n",
    "real_imgs = []\n",
    "fake_imgs = []\n",
    "for p in params_extra:\n",
    "    real_imgs.append(lambda p1=p: dataset.get_data_for_params(p1, N=N)[0])\n",
    "    fake_imgs.append(lambda p1=p: evaluation.generate_samples_params(wgan, p1, nsamples=N, checkpoint=checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, score_extra, list_plotdata_stats = evaluation.compute_plots_for_params(params_extra, real_imgs, fake_imgs, param_str=title_func, ylims=ylims, log=False, confidence='std', lim=(0, 0.4), fractional_difference=fractional_difference, lenstools=lenstools, cut=cut, box_l=box_l, bin_k=bin_k, thresholds_minkowski=thresholds_minkowski)\n",
    "plt.close(fig)\n",
    "write_pickle('compute_plots_for_params__extrapolation.pkl', list_plotdata_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate 1D distribution tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load.load_params_dataset(filename=dataset_test_name, batch=N, sorted=True, shape=[ns, ns])\n",
    "params_test = dataset.get_different_params()\n",
    "real_imgs = []\n",
    "fake_imgs = []\n",
    "for p in params_test:\n",
    "    real_imgs.append(lambda p1=p: dataset.get_data_for_params(p1, N=N)[0])\n",
    "    fake_imgs.append(lambda p1=p: evaluation.generate_samples_params(wgan, p1, nsamples=N, checkpoint=checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wass_pixel, wass_peaks = evaluation.get_1D_sample_tests(params_test, real_imgs, fake_imgs)\n",
    "do = dict(wass_pixel=wass_pixel, wass_peaks=wass_peaks, params=params_test)\n",
    "write_pickle('mass_1D_tests__testset.pkl', do)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## MS-SSIM structural similarity index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_ssim_for_dataset(dataset_name, N=2000):\n",
    "    dataset = load.load_params_dataset(filename=dataset_name, batch=N, sorted=True, shape=[ns, ns])\n",
    "    real_imgs = []\n",
    "    fake_imgs = []\n",
    "    for p in dataset.get_different_params():\n",
    "        real_imgs.append(lambda p1=p: dataset.get_data_for_params(p1, N=N)[0])\n",
    "        fake_imgs.append(lambda p1=p: evaluation.generate_samples_params(wgan, p1, nsamples=N, checkpoint=checkpoint))\n",
    "    s_fake_all, s_real_all = evaluation.compute_ssim_score(fake_imgs, real_imgs)\n",
    "    dict_ssim = dict(s_fake_all=s_fake_all, s_real_all=s_real_all, params_cosmo=dataset.get_different_params())\n",
    "    return dict_ssim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dict_ssim_trainset = get_ssim_for_dataset(dataset_train_name, N=N)\n",
    "write_pickle('dict_ssim_trainset.pkl', dict_ssim_trainset)\n",
    "dict_ssim_testset = get_ssim_for_dataset(dataset_test_name, N=N)\n",
    "write_pickle('dict_ssim_testset.pkl', dict_ssim_testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Correlation matrix analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from cosmotools.metric import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# N = 5000\n",
    "cut_corr = [300, 6000]\n",
    "bin_k = 20\n",
    "N=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_correlation_matrices_for_dataset(dataset_name, N=2000):\n",
    "    \n",
    "    dataset = load.load_params_dataset(filename=dataset_name, batch=N, sorted=True, shape=[ns, ns])\n",
    "    params_cosmo = dataset.get_different_params()\n",
    "    dict_res = {'covmat_real':[], 'covmat_fake':[],'corrmat_real':[], 'corrmat_fake':[]}\n",
    "    for i, p in enumerate(params_cosmo):\n",
    "        printt('param {}/{} {}'.format(i, len(params_cosmo), dataset_name))\n",
    "        real_imgs = dataset.get_data_for_params(p, N)[0]\n",
    "        fake_imgs = evaluation.generate_samples_params(wgan, p, nsamples=N, checkpoint=checkpoint)\n",
    "        corrmat_real, covmat_real, _ = stats.psd_correlation_lenstools(real_imgs, cut=cut_corr, box_l=box_l, bin_k=bin_k)\n",
    "        corrmat_fake, covmat_fake, _ = stats.psd_correlation_lenstools(fake_imgs, cut=cut_corr, box_l=box_l, bin_k=bin_k)\n",
    "        dict_res['corrmat_real'] += [corrmat_real]\n",
    "        dict_res['corrmat_fake'] += [corrmat_fake]\n",
    "        dict_res['covmat_real'] += [covmat_real]\n",
    "        dict_res['covmat_fake'] += [covmat_fake]\n",
    "\n",
    "    return dict_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c_test = get_correlation_matrices_for_dataset(dataset_name=dataset_test_name, N=N)\n",
    "c_train = get_correlation_matrices_for_dataset(dataset_name=dataset_train_name, N=N)\n",
    "dict_out = dict(c_train=c_train, c_test=c_test, cut_corr=cut_corr, bin_k=bin_k)\n",
    "write_pickle('corr_results.pkl', dict_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Frechet Inception Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load regressor\n",
    "regressor_path = os.path.join(global_path, 'Kids_Regressor_128_smart_2D_mac_checkpoints/')\n",
    "N = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_frechet_results_for_dataset(dataset_name, N=2000):\n",
    "    dataset = load.load_params_dataset(filename=dataset_name, batch=N, sorted=True, shape=[ns, ns])\n",
    "        # Define parameters\n",
    "    params = dataset.get_different_params()\n",
    "    params = np.array(params)\n",
    "    # Generate images\n",
    "    real_imgs = []\n",
    "    fake_imgs = []\n",
    "    for i, p in enumerate(params):\n",
    "        printt('param {}/{}'.format(i, len(params)))\n",
    "        real_imgs.append(dataset.get_data_for_params(p, N=N)[0])\n",
    "        fake_imgs.append(evaluation.generate_samples_params(wgan, p, nsamples=N, checkpoint=checkpoint))\n",
    "\n",
    "    fids, fig, pred_params, params, features = evaluation.compute_plot_fid(real_imgs, fake_imgs, params, regressor_path, batch_size=N, checkpoint=140000, lims=[[0.05, 0.5], [0.4, 1.4]], alpha=0.025)\n",
    "    plt.close(fig)\n",
    "    dict_pickle = dict(fids=fids, pred_params=pred_params, params=params, features=features)\n",
    "    return dict_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "wgan = GANsystem(CosmoConditionalParamWGAN, params)\n",
    "dict_pickle_test = get_frechet_results_for_dataset(dataset_name=dataset_test_name, N=N)\n",
    "wgan = GANsystem(CosmoConditionalParamWGAN, params)\n",
    "dict_pickle_train = get_frechet_results_for_dataset(dataset_name=dataset_train_name, N=N)\n",
    "dict_pickle_full = dict(dict_pickle_train=dict_pickle_train, dict_pickle_test=dict_pickle_test, N=N)\n",
    "write_pickle('results_fid.pkl', dict_pickle_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define statistics parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "list_stat_all = ['psd', 'peak_count', 'mass_hist', 'bispectrum', 'minkowski_V0', 'minkowski_V1', 'minkowski_V2', 'ssim_sig', 'corr_fro_norm', 'corr_diff', 'fid', 'wasserstein_mass_hist']\n",
    "stat_specs = {s:{'cmap':plt.cm.viridis} for s in list_stat_all}\n",
    "\n",
    "stat_specs['psd']['name_math'] = r'$C_\\ell$'\n",
    "stat_specs['psd']['ylabel'] = r'$C_\\ell \\cdot \\ell \\cdot (\\ell+1) \\ /  \\ (2\\pi)$'\n",
    "stat_specs['psd']['xlabel'] = r'$\\ell$'\n",
    "stat_specs['psd']['xlim'] = [300,3000] \n",
    "stat_specs['psd']['ylim'] = [0, 5e-5]\n",
    "stat_specs['psd']['yscale'] = 'linear'\n",
    "stat_specs['psd']['margin_left'] = 0.2\n",
    "stat_specs['psd']['difference_range'] = [0, 0.05]\n",
    "stat_specs['psd']['difference_title'] = 'fractional difference\\n'+r'power spectrum $C_\\ell$'\n",
    "\n",
    "\n",
    "stat_specs['peak_count']['name_math'] = r'$N_{\\rm{peaks}}$'\n",
    "stat_specs['peak_count']['ylabel'] = r'$N_{\\rm{peaks}}$'\n",
    "stat_specs['peak_count']['xlabel'] = r'$\\kappa$'\n",
    "stat_specs['peak_count']['xlim'] = [0.025, 0.09] \n",
    "stat_specs['peak_count']['ylim'] = [0, 1e2]\n",
    "stat_specs['peak_count']['yscale'] = 'linear'\n",
    "\n",
    "stat_specs['mass_hist']['name_math'] = r'$N_{\\rm{pixels}}$'\n",
    "stat_specs['mass_hist']['ylabel'] = r'$N_{\\rm{pixels}}$'\n",
    "stat_specs['mass_hist']['xlabel'] = r'$\\kappa$'\n",
    "stat_specs['mass_hist']['xlim'] = [0.02, 0.08] \n",
    "stat_specs['mass_hist']['ylim'] = [0, 3e3]\n",
    "stat_specs['mass_hist']['yscale'] = 'linear'\n",
    "stat_specs['mass_hist']['difference_range'] = [0, 0.05]\n",
    "stat_specs['mass_hist']['difference_title'] = 'fractional difference\\n'+r'power spectrum $N_{pix}$'\n",
    "\n",
    "stat_specs['minkowski_V0']['name_math'] = r'V_0'\n",
    "stat_specs['minkowski_V0']['ylabel'] = r'Minkowski $V_0$'\n",
    "stat_specs['minkowski_V0']['xlabel'] = r'$\\kappa$'\n",
    "stat_specs['minkowski_V0']['xlim'] = [0.02, 0.08] \n",
    "stat_specs['minkowski_V0']['ylim'] = [0, 1.05]\n",
    "stat_specs['minkowski_V0']['yscale'] = 'linear'\n",
    "\n",
    "stat_specs['minkowski_V1']['name_math'] = r'V_1'\n",
    "stat_specs['minkowski_V1']['ylabel'] = r'Minkowski $V_1$'\n",
    "stat_specs['minkowski_V1']['xlabel'] = r'$\\kappa$'\n",
    "stat_specs['minkowski_V1']['xlim'] = [0.02, 0.08] \n",
    "stat_specs['minkowski_V1']['ylim'] = [0, 0.1]\n",
    "stat_specs['minkowski_V1']['yscale'] = 'linear'\n",
    "\n",
    "stat_specs['minkowski_V2']['name_math'] = r'V_2'\n",
    "stat_specs['minkowski_V2']['ylabel'] = r'Minkowski $V_2$'\n",
    "stat_specs['minkowski_V2']['xlabel'] = r'$\\kappa$'\n",
    "stat_specs['minkowski_V2']['xlim'] = [0.02, 0.08]  \n",
    "stat_specs['minkowski_V2']['ylim'] = [-0.02, 0.012]\n",
    "stat_specs['minkowski_V2']['yscale'] = 'linear'\n",
    "\n",
    "stat_specs['bispectrum']['name_math'] = r'$B_{\\ell}$'\n",
    "stat_specs['bispectrum']['ylabel'] = r'$B_{\\ell} \\cdot \\ell \\cdot (\\ell+1) \\cdot (\\ell+2) \\ /  \\ (2\\pi)$'\n",
    "stat_specs['bispectrum']['xlabel'] = r'$\\ell$'\n",
    "stat_specs['bispectrum']['xlim'] = [300, 3000]  \n",
    "stat_specs['bispectrum']['ylim'] = [0., 2e-8]\n",
    "stat_specs['bispectrum']['yscale'] = 'linear'\n",
    "stat_specs['bispectrum']['difference_range'] = [0, 0.2]\n",
    "stat_specs['bispectrum']['difference_title'] = 'fractional difference\\n'+r'bispectrum $B_\\ell$'\n",
    "\n",
    "stat_specs['ssim_sig']['name_math'] = r'$\\sigma [\\rm{SSIM}]$'\n",
    "stat_specs['ssim_sig']['difference_range'] = [-1, 1]\n",
    "stat_specs['ssim_sig']['difference_title'] = 'difference significance\\n'+r'Structural Similarity Index SSIM'\n",
    "stat_specs['ssim_sig']['cmap'] = plt.cm.Spectral_r\n",
    "\n",
    "stat_specs['corr_fro_norm']['name_math'] = r'fro norm'\n",
    "stat_specs['corr_fro_norm']['difference_range'] = [0,0.5]\n",
    "stat_specs['corr_fro_norm']['difference_title'] = 'fractional difference\\n'+r'correlation matrix $R_{\\ell\\ell^\\prime}$'\n",
    "stat_specs['corr_fro_norm']['cmap'] = plt.cm.viridis\n",
    "\n",
    "stat_specs['corr_diff']['name_math']  = 'diff'\n",
    "stat_specs['corr_diff']['difference_range']  = [0,0.08]\n",
    "stat_specs['corr_diff']['difference_title']  = r'fractional difference $\\rm{Corr}$'\n",
    "\n",
    "stat_specs['fid']['name_math']  = 'FID'\n",
    "stat_specs['fid']['difference_range']  = [0,3]\n",
    "stat_specs['fid']['difference_title']  = 'Fréchet ' + 'Distance FID$^{1/2}$' + '\\non CNN regressor output'\n",
    "stat_specs['fid']['cmap'] = plt.cm.viridis\n",
    "\n",
    "stat_specs['wasserstein_mass_hist']['name_math']  = 'Wasserstein1D'\n",
    "stat_specs['wasserstein_mass_hist']['difference_range']  = [0,5e-2]\n",
    "stat_specs['wasserstein_mass_hist']['difference_title']  = 'normalised Wasserstein-1 distance\\npixel values'\n",
    "stat_specs['wasserstein_mass_hist']['cmap'] = plt.cm.viridis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# FIGURE statistics for interpolated cosmologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_title_str(par):\n",
    "    return r'$\\Omega_m={:2.2f} \\quad \\sigma_8={:2.2f}$'.format(par[0], par[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_frac_diff(y1, y2):\n",
    "    f = (y1-y2)/y1\n",
    "    return f\n",
    "\n",
    "def get_dynamic_range_difference(y1, y2):\n",
    "    ym = (y1+y2)/2.\n",
    "    return (y1-y2)/np.abs(np.max(ym)-np.min(ym))\n",
    "\n",
    "def get_dynamic_range_difference2(y1, y2):\n",
    "    ym = (y1+y2)/2.\n",
    "    return 2*(y1-y2)/(y2+(np.max(ym)-np.min(ym)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_single_statistic_with_ratio(ax, x, y_real, y_gen):\n",
    "    \n",
    "    \n",
    "    qs=[32, 50, 68]\n",
    "    ypr = np.percentile(y_real, q=qs, axis=0)\n",
    "    ypg = np.percentile(y_gen, q=qs, axis=0)\n",
    "    fd = get_frac_diff(ypg[1], ypr[1])\n",
    "#     fd = get_dynamic_range_difference2(ypg[1], ypr[1])\n",
    "    ax[0].plot(x, ypr[1], color=color_real, label='N-body')\n",
    "    ax[0].fill_between(x, ypr[0], ypr[2], alpha=alpha, color=color_real)\n",
    "    ax[0].plot(x, ypg[1], color=color_gen, label='GAN')\n",
    "    ax[0].fill_between(x, ypg[0], ypg[2], alpha=alpha, color=color_gen)   \n",
    "    ax[1].plot(x, fd, color=color_ratio)\n",
    "    ax[1].set(ylim=ylim_ratio, yticks=yticks_ratio)\n",
    "    ax[1].fill_between(x, -0.05, 0.05, color='gray', alpha=0.1)\n",
    "    \n",
    "    for a in ax.ravel(): a.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stats_interpolation = read_pickle('compute_plots_for_params__interpolation.pkl')\n",
    "param_ids = [1, 5, 4, 2]\n",
    "# param_ids = range(7)\n",
    "n_par = len(param_ids)\n",
    "alpha = 0.1\n",
    "color_real = 'b'\n",
    "color_gen = 'r'\n",
    "color_ratio = 'k'\n",
    "fontsize_title=18\n",
    "fontsize_ylabel=20\n",
    "fontsize_ticks=14\n",
    "yticks_ratio = [-0.1, 0, 0.1]\n",
    "ylim_ratio = [-0.2, 0.2]\n",
    "color_testset='pink'\n",
    "color_trainset='c'\n",
    "markersize_testset=250\n",
    "markersize_trainset=150\n",
    "fontsize_legend=20\n",
    "params_highlight_labels = ['A', 'B', 'C', 'D']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_multiple_statistic_with_ratio(ids, stats, stats_name, show_legend=False):\n",
    "    \n",
    "    nx, ny = 2, len(ids); \n",
    "    fig, ax = plt.subplots(nx, ny, figsize=(ny * 6, nx * 2.5), squeeze=False, sharex=True, gridspec_kw={'hspace':0.0, 'wspace':0.15, 'height_ratios': [3,1]}); \n",
    "        \n",
    "    spec=stat_specs[stats_name]\n",
    "    spec.setdefault('margin_left', 0.1)\n",
    "    \n",
    "    yr, yg = 'y_real', 'y_fake'\n",
    "    \n",
    "    for i, j in enumerate(ids):\n",
    "        stat = stats[j]\n",
    "            \n",
    "        plot_single_statistic_with_ratio(ax=ax[:,i], x=stat[stats_name]['x'], y_real=stat[stats_name][yr], y_gen=stat[stats_name][yg])\n",
    "        ax[0,i].set_yscale(spec['yscale'])\n",
    "        if i>0:\n",
    "            for a in ax[:,i]: a.set_yticklabels([])\n",
    "                \n",
    "        ax[1,i].set_xlabel(spec['xlabel'], fontsize=fontsize_ylabel)\n",
    "        ax[0,i].set_title(get_title_str(params_inter[j]), fontsize=fontsize_title)\n",
    "        ax[0,i].set_xlim(spec['xlim'])\n",
    "        ax[0,i].set_ylim(spec['ylim'])\n",
    "        for a in ax[:,i]:\n",
    "            a.tick_params(axis='both', labelsize=fontsize_ticks)\n",
    "        pos_x = spec['xlim'][0] + (spec['xlim'][1]-spec['xlim'][0])*0.1\n",
    "        pos_y = spec['ylim'][0] + (spec['ylim'][1]-spec['ylim'][0])*0.85\n",
    "        ax[0,i].scatter(pos_x, pos_y, marker='D', s=markersize_testset*2, c=color_testset, edgecolor='k', zorder=200)\n",
    "        ax[0,i].text(pos_x, pos_y, params_highlight_labels[i], zorder=201, fontsize=16, ha='center', va='center', color='k')\n",
    "\n",
    "\n",
    "    ax[0,0].get_yaxis().get_major_formatter().set_useMathText(True)\n",
    "    ax[0,0].get_yaxis().get_major_formatter().set_powerlimits((0, 0))    \n",
    "    ax[0,0].set_ylabel(spec['ylabel'], fontsize=fontsize_ylabel)\n",
    "    if show_legend:\n",
    "        ax[0,0].legend(loc='upper center', bbox_to_anchor=(0.72, 1), shadow=False, ncol=1, fontsize=fontsize_legend)\n",
    "\n",
    "    return fig\n",
    "        \n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list_stat = ['mass_hist', 'peak_count']\n",
    "for i, stat in enumerate(list_stat):\n",
    "    fig = plot_multiple_statistic_with_ratio(ids=param_ids, stats=stats_interpolation, stats_name=stat, show_legend=i == 0)\n",
    "    fig.savefig('figure_interpolated_{}.pdf'.format(stat), dpi=200)\n",
    "list_stat = ['psd', 'bispectrum']\n",
    "for i, stat in enumerate(list_stat):\n",
    "    fig = plot_multiple_statistic_with_ratio(ids=param_ids, stats=stats_interpolation, stats_name=stat, show_legend=i == 0)\n",
    "    fig.savefig('figure_interpolated_{}.pdf'.format(stat), dpi=200)\n",
    "list_stat = ['minkowski_V0', 'minkowski_V1', 'minkowski_V2']\n",
    "for i, stat in enumerate(list_stat):\n",
    "    fig = plot_multiple_statistic_with_ratio(ids=param_ids, stats=stats_interpolation, stats_name=stat, show_legend=i == 0)\n",
    "    fig.savefig('figure_interpolated_{}.pdf'.format(stat), dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#  FIGURE grid train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_scatter = dict(cmap=plt.cm.Spectral_r, edgecolor='k', vmin=0, vmax=None, zorder=100)\n",
    "fontsize_label=20\n",
    "fontsize_legend=16\n",
    "fontsize_title=19\n",
    "fontsize_ticks=16\n",
    "lim_omega_m=[0.08, 0.52]\n",
    "lim_sigma_8=[0.4, 1.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_grid_train_test(test_params, train_params, labels=['$\\Omega_m$', '$\\sigma_8$'], params_text=None, kw_scatter={}):\n",
    "        \n",
    "    nx, ny = 1, 1; \n",
    "    fig, ax = plt.subplots(nx, ny, figsize=(ny * 6, nx * 5), sharey=True, sharex=True, squeeze=False, gridspec_kw={'hspace':0.1, 'wspace':0.1}); axc=ax[0,0]; axl=ax[0,:];\n",
    "    s=axc.scatter(test_params[:, 0], test_params[:, 1], c=color_testset, marker='D', s=250, label='test set',  **kw_scatter)\n",
    "    axc.scatter(train_params[:, 0], train_params[:, 1], c=color_trainset, marker='o', s=150, label='training set', **kw_scatter)\n",
    "    axc.set_xlabel(labels[0], fontsize=fontsize_label)\n",
    "    axc.set_ylabel(labels[1], fontsize=fontsize_label)\n",
    "    axc.legend(fontsize=fontsize_legend)\n",
    "    axc.set_title('simulation sets', fontsize=fontsize_title)\n",
    "    axc.grid(True)\n",
    "    axc.tick_params(axis='both', which='major', labelsize=fontsize_ticks)\n",
    "    axc.set(xlim=lim_omega_m, ylim=lim_sigma_8)\n",
    "    if params_text is not None:\n",
    "        for i, p in enumerate(params_text):\n",
    "            axc.text(p[0], p[1], params_highlight_labels[i], zorder=100, fontsize=fontsize_testset_letter, ha='center', va='center', color='k')\n",
    "    fig.subplots_adjust(left=0.15)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params_text=params_inter[param_ids]\n",
    "fontsize_testset_letter = 11\n",
    "print(params_text)\n",
    "kw_scatter = dict(edgecolor='k', zorder=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig = plot_grid_train_test(params_test, params_train, params_text=params_text, kw_scatter=kw_scatter)\n",
    "fig.savefig('figure_grid_test_train.pdf', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIGURE grid accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fractional differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_frac_diff(stats, list_stat_name):\n",
    "    \n",
    "    avg = np.nanmean\n",
    "    acc = {s: np.zeros(len(stats)) for s in list_stat_name}\n",
    "        \n",
    "    for j, stat_name in enumerate(list_stat_name):\n",
    "        for i in range(len(stats)):\n",
    "            x = stats[i][stat_name]['x']\n",
    "            select = (x>stat_specs[stat_name]['xlim'][0]) & (x<stat_specs[stat_name]['xlim'][1])\n",
    "            yf = avg(stats[i][stat_name]['y_fake'], axis=0)[select]\n",
    "            yr = avg(stats[i][stat_name]['y_real'], axis=0)[select]\n",
    "            diff = get_frac_diff(yf, yr)\n",
    "#             diff = get_dynamic_range_difference2(yf, yr)\n",
    "            acc[stat_name][i] = avg(np.abs(diff))\n",
    "    return acc\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_inter = read_pickle('compute_plots_for_params__interpolation.pkl')\n",
    "stats_extra = read_pickle('compute_plots_for_params__extrapolation.pkl')\n",
    "stats_train = read_pickle('compute_plots_for_params__trainset.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stats = ['psd', 'bispectrum', 'minkowski_V0', 'minkowski_V1', 'minkowski_V2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_extra = calculate_accuracy_frac_diff(stats_extra, list_stats)\n",
    "accuracy_inter = calculate_accuracy_frac_diff(stats_inter, list_stats)\n",
    "accuracy_train = calculate_accuracy_frac_diff(stats_train, list_stats)\n",
    "params_test = np.vstack([params_inter, params_extra])\n",
    "accuracy_test = {s: np.concatenate([accuracy_inter[s], accuracy_extra[s]]) for s in list_stats}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wasserstein distance for histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_mass1D_testset = read_pickle('mass_1D_tests__testset.pkl')\n",
    "dict_mass1D_trainset = read_pickle('mass_1D_tests__trainset.pkl')\n",
    "accuracy_test['wasserstein_mass_hist'] = dict_mass1D_testset['wass_pixel']\n",
    "accuracy_train['wasserstein_mass_hist'] = dict_mass1D_trainset['wass_pixel']\n",
    "accuracy_test['wasserstein_peak_count'] = dict_mass1D_testset['wass_peaks']\n",
    "accuracy_train['wasserstein_peak_count'] = dict_mass1D_trainset['wass_peaks']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ssim_significance(s_fake_all, s_real_all):\n",
    "    s_fake = s_fake_all.mean(axis=1)\n",
    "    s_real = s_real_all.mean(axis=1)\n",
    "    s_fake_std = s_fake_all.std(axis=1)#/np.sqrt(s_fake_all.shape[1])\n",
    "    s_real_std = s_real_all.std(axis=1)#/np.sqrt(s_fake_all.shape[1])\n",
    "#     sig = (s_fake-s_real)/np.sqrt(s_fake_std**2+s_real_std**2)\n",
    "    sig = (s_fake-s_real)/((s_fake_std+s_real_std)/2)\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ssim_trainset = read_pickle('dict_ssim_trainset.pkl')\n",
    "dataset = load.load_params_dataset(filename=dataset_train_name, batch=N, sorted=True, shape=[ns, ns])\n",
    "dict_ssim_trainset['params_cosmo'] = params_cosmo=dataset.get_different_params()\n",
    "\n",
    "dict_ssim_testset = read_pickle('dict_ssim_testset.pkl')\n",
    "dataset = load.load_params_dataset(filename=dataset_test_name, batch=N, sorted=True, shape=[ns, ns])\n",
    "dict_ssim_testset['params_cosmo'] = params_cosmo=dataset.get_different_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_ssim_train = get_ssim_significance(dict_ssim_trainset['s_fake_all'], dict_ssim_trainset['s_real_all'])\n",
    "sig_ssim_test = get_ssim_significance(dict_ssim_testset['s_fake_all'], dict_ssim_testset['s_real_all'])\n",
    "accuracy_test['ssim_sig']=sig_ssim_test\n",
    "accuracy_train['ssim_sig']=sig_ssim_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fro_norm(list_corr):\n",
    "    fro_norm = np.zeros(len(list_corr))\n",
    "    for i, c in enumerate(list_corr):\n",
    "        n=c.shape[0]\n",
    "        fro_norm[i] = np.linalg.norm(c)\n",
    "    return fro_norm\n",
    "\n",
    "def get_matrix_difference(corr):\n",
    "    mat_diff = np.zeros(len(corr['corrmat_fake']))\n",
    "    from scipy.stats import median_abs_deviation\n",
    "    for i, c in enumerate(corr['corrmat_fake']):\n",
    "        n = corr['corrmat_fake'][i].shape[0]\n",
    "        cfo = corr['corrmat_fake'][i][~np.eye(n).astype(np.bool)]\n",
    "        cro = corr['corrmat_real'][i][~np.eye(n).astype(np.bool)]\n",
    "        diff = (cfo-cro)/cro\n",
    "        diff = diff[np.isfinite(diff)]\n",
    "        mat_diff[i] = median_abs_deviation(diff.flatten())\n",
    "    return mat_diff\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_corr = read_pickle('corr_results.pkl')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fro_fake_train = get_fro_norm(dict_corr['c_train']['corrmat_fake'])\n",
    "fro_real_train = get_fro_norm(dict_corr['c_train']['corrmat_real'])\n",
    "fro_fake_test = get_fro_norm(dict_corr['c_test']['corrmat_fake'])\n",
    "fro_real_test = get_fro_norm(dict_corr['c_test']['corrmat_real'])\n",
    "accuracy_test['corr_fro_norm']=np.abs(fro_fake_test-fro_real_test)/fro_real_test\n",
    "accuracy_train['corr_fro_norm']=np.abs(fro_fake_train-fro_real_train)/fro_real_train\n",
    "list_stats = ['corr_fro_norm', 'ssim_sig', 'psd', 'bispectrum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test['corr_diff']=get_matrix_difference(dict_corr['c_test'])\n",
    "accuracy_train['corr_diff']=get_matrix_difference(dict_corr['c_train'])\n",
    "list_stats = ['ssim_sig', 'psd', 'corr_diff', 'bispectrum']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frechet Inception Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein(mu1, mu2, sig1, sig2):\n",
    "    from scipy.linalg import sqrtm\n",
    "    w = np.linalg.norm(mu1 - mu2)**2 + np.linalg.norm(sqrtm(sig1)-sqrtm(sig2))**2\n",
    "    n = len(mu1)\n",
    "    w = w/n\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcualte_fid(pred_params):\n",
    "    w = np.zeros(pred_params.shape[0])\n",
    "    for i in range(pred_params.shape[0]):\n",
    "        pred_real = pred_params[i, 0, :, :] \n",
    "        pred_fake = pred_params[i, 1, :, :] \n",
    "        mean_pred_real = pred_real.mean(axis=0)\n",
    "        stdv_pred_real = pred_real.std(axis=0)\n",
    "        pred_real -= mean_pred_real\n",
    "        pred_fake -= mean_pred_real\n",
    "        pred_real /= stdv_pred_real\n",
    "        pred_fake /= stdv_pred_real\n",
    "#         print(pred_real.std(axis=0))\n",
    "        mean_real, cov_real = np.mean(pred_real, axis=0), np.cov(pred_real.T)\n",
    "        mean_fake, cov_fake = np.mean(pred_fake, axis=0), np.cov(pred_fake.T)\n",
    "#         print(cov_real, cov_fake)\n",
    "        wass = wasserstein(mu1=mean_real, mu2=mean_fake, sig1=cov_real, sig2=cov_fake)\n",
    "        w[i] = np.sqrt(wass)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_regression = read_pickle('results_fid.pkl')\n",
    "accuracy_test['fid'] = calcualte_fid(dict_regression['dict_pickle_test']['pred_params'])\n",
    "accuracy_train['fid'] = calcualte_fid(dict_regression['dict_pickle_train']['pred_params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display values for some scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_inter[param_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_params_show = [4,7,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(list_params_show):\n",
    "    print('param={} {:2.2f}'.format(params_highlight_labels[i], accuracy_test['corr_fro_norm'][p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(list_params_show):\n",
    "    print('param={} {:2.2f}'.format(params_highlight_labels[i], accuracy_test['ssim_sig'][p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(list_params_show):\n",
    "    print('param={} {:2.2f}'.format(params_highlight_labels[i], accuracy_test['wasserstein_mass_hist'][p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(list_params_show):\n",
    "    print('param={} {:2.2f}'.format(params_highlight_labels[i], accuracy_test['wasserstein_peak_count'][p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(list_params_show):\n",
    "    print('param={} {:2.2f}'.format(params_highlight_labels[i], accuracy_test['fid'][p]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot combined figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid_accuracy(list_stats, test_scores, test_params, train_scores, train_params, thresholds=None, labels=['$\\Omega_m$', '$\\sigma_8$'], kw_scatter={}, gridspec_kw={'hspace':0.05, 'wspace':0.05}, layout=None):\n",
    "    from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "    ns = len(list_stats)\n",
    "    nx, ny = 1, ns+1; \n",
    "    if layout is None:\n",
    "        nx, ny = 1, ns; \n",
    "    else:\n",
    "        nx, ny = layout\n",
    "    fig, ax = plt.subplots(nx, ny, figsize=(ny * 6, nx * 5), sharey=True, sharex=True, squeeze=False, gridspec_kw=gridspec_kw); axc=ax[0,0]; axl=ax[0,:];\n",
    "\n",
    "    axf = ax.ravel()\n",
    "    for i, stat in enumerate(list_stats):\n",
    "        ss=stat_specs[stat]\n",
    "        axf[i].grid(True)\n",
    "        s=axf[i].scatter(test_params[:, 0], test_params[:, 1], c=test_scores[stat], marker='D', s=250, vmin=ss['difference_range'][0], vmax=ss['difference_range'][1], cmap=ss['cmap'], **kw_scatter)\n",
    "        axf[i].scatter(train_params[:, 0], train_params[:, 1], c=train_scores[stat], marker='o', s=150, vmin=ss['difference_range'][0], vmax=ss['difference_range'][1], cmap=ss['cmap'], **kw_scatter)\n",
    "        axf[i].set_xlabel(labels[0], fontsize=fontsize_label)\n",
    "        if i ==0 or i==3:\n",
    "            axf[i].set_ylabel(labels[1], fontsize=fontsize_label)\n",
    "        cbaxes = inset_axes(axf[i], width=\"50%\", height=\"7%\", loc='upper right', borderpad=1.4) \n",
    "        fig.colorbar(s, orientation=\"horizontal\", cax=cbaxes)\n",
    "        cbaxes.tick_params(axis='both', which='major', labelsize=fontsize_ticks)\n",
    "        axf[i].set_title(ss['difference_title'], fontsize=fontsize_title)\n",
    "        axf[i].tick_params(axis='both', which='major', labelsize=fontsize_ticks)\n",
    "        axf[i].set(xlim=lim_omega_m, ylim=lim_sigma_8)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stats = ['ssim_sig',  'fid', 'wasserstein_mass_hist', 'psd', 'corr_fro_norm', 'bispectrum']\n",
    "kw_scatter = dict(edgecolor='k', zorder=100)\n",
    "stat_specs['fid']['difference_range']  = [0,5] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_grid_accuracy(list_stats, accuracy_test, params_test, accuracy_train, params_train, kw_scatter=kw_scatter, layout=[2,3], gridspec_kw={'hspace':0.5, 'wspace':0.1})\n",
    "fig.savefig('figure_grid_diff.pdf', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# FIGURE correlation matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def corr_combine(c1, c2):\n",
    "    return np.tril(c1)+np.triu(c2) - np.eye(c1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_matrices_for_params(params, dict_corr, kw_pcolor):\n",
    "\n",
    "    nx, ny = 1, len(params); \n",
    "    fig, ax = plt.subplots(nx, ny, figsize=(ny * 6, nx * 6),  sharex=True, sharey=True, squeeze=False, gridspec_kw={'wspace':0.05}); axc=ax[0,0]; axl=ax[0,:];\n",
    "    for i in range(ny):\n",
    "        c_comb = corr_combine(dict_corr['corrmat_real'][i], dict_corr['corrmat_fake'][i])\n",
    "        s=ax[0,i].pcolormesh(l_edges, l_edges, c_comb, **kw_pcolor)\n",
    "        if i==0:\n",
    "            ax[0,i].set_ylabel(r'$\\ell$', fontsize=fontsize_label)\n",
    "        ax[0,i].set_xlabel(r'$\\ell$', fontsize=fontsize_label)\n",
    "        pos_x = cut_corr[0] + (cut_corr[1]-cut_corr[0])*0.2\n",
    "        pos_y = cut_corr[0] + (cut_corr[1]-cut_corr[0])*0.85\n",
    "        ax[0,i].text(pos_x, pos_y, 'N-body', zorder=201, fontsize=fontsize_tag, ha='left', va='bottom', color='w')\n",
    "\n",
    "        pos_x = cut_corr[0] + (cut_corr[1]-cut_corr[0])*0.7\n",
    "        pos_y = cut_corr[0] + (cut_corr[1]-cut_corr[0])*0.07\n",
    "        ax[0,i].text(pos_x, pos_y, 'GAN', zorder=201, fontsize=fontsize_tag, ha='left', va='bottom', color='w')\n",
    "            \n",
    "        pos_x = cut_corr[0] + (cut_corr[1]-cut_corr[0])*0.1\n",
    "        pos_y = cut_corr[0] + (cut_corr[1]-cut_corr[0])*0.9\n",
    "        ax[0,i].scatter(pos_x, pos_y, marker='D', s=markersize_testset*2, c=color_testset, edgecolor='k', zorder=200)\n",
    "        ax[0,i].text(pos_x, pos_y, params_highlight_labels[i], zorder=201, fontsize=16, ha='center', va='center', color='k')\n",
    "        ax[0,i].tick_params(axis='both', labelsize=fontsize_ticks)\n",
    "        \n",
    "        ax[0,i].plot(l_edges, l_edges, c='k', lw=linewidth_diag)\n",
    "\n",
    "    # [left, bottom, width, height] \n",
    "    cbaxes = fig.add_axes([0.91, 0.2, 0.01, 0.6]) \n",
    "    fig.colorbar(s, orientation=\"vertical\", cax=cbaxes)\n",
    "    cbaxes.tick_params(axis='both', which='major', labelsize=fontsize_ticks)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dict_corr = read_pickle('corr_results.pkl')  \n",
    "# dict_corr['cut_corr'] = [300,3000] # remove after rerun\n",
    "# dict_corr['bin_k'] = 20 # remove after rerun\n",
    "cut_corr = dict_corr['cut_corr']\n",
    "bin_k = dict_corr['bin_k']\n",
    "l_edges = np.linspace(dict_corr['cut_corr'][0], dict_corr['cut_corr'][1], dict_corr['bin_k'])\n",
    "fontsize_label=18\n",
    "fontsize_tag=32\n",
    "fontsize_ticks=14\n",
    "linewidth_diag=1\n",
    "N=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = load.load_params_dataset(filename=dataset_train_name, batch=N, sorted=True, shape=[ns, ns])\n",
    "params_train = dataset.get_different_params()\n",
    "dataset = load.load_params_dataset(filename=dataset_test_name, batch=N, sorted=True, shape=[ns, ns])\n",
    "params_test = dataset.get_different_params()\n",
    "kw_pcolor = {'cmap':plt.cm.viridis, 'vmin':0.4, 'vmax':1, 'rasterized':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig = plot_matrices_for_params(params=params_inter[param_ids], dict_corr=dict_corr['c_test'], kw_pcolor=kw_pcolor)\n",
    "fig.savefig('figure_corrmat.pdf', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIGURE regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frechet_results_for_dataset(dataset_name, N=2000):\n",
    "    dataset = load.load_params_dataset(filename=dataset_name, batch=N, sorted=True, shape=[ns, ns])\n",
    "        # Define parameters\n",
    "    params = dataset.get_different_params()\n",
    "    params = np.array(params)\n",
    "    # Generate images\n",
    "    real_imgs = []\n",
    "    fake_imgs = []\n",
    "    for i, p in enumerate(params):\n",
    "        printt('param {}/{}'.format(i, len(params)))\n",
    "        real_imgs.append(dataset.get_data_for_params(p, N=N)[0])\n",
    "        fake_imgs.append(evaluation.generate_samples_params(wgan, p, nsamples=N, checkpoint=checkpoint))\n",
    "\n",
    "    fids, fig, pred_params, params, features = evaluation.compute_plot_fid(real_imgs, fake_imgs, params, regressor_path, batch_size=N, checkpoint=140000, lims=[[0.05, 0.5], [0.4, 1.4]], alpha=0.025)\n",
    "    plt.close(fig)\n",
    "    dict_pickle = dict(fids=fids, pred_params=pred_params, params=params, features=features)\n",
    "    return dict_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load regressor\n",
    "N = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "wgan = GANsystem(CosmoConditionalParamWGAN, params)\n",
    "dict_pickle_test = get_frechet_results_for_dataset(dataset_name=dataset_test_name, N=N)\n",
    "wgan = GANsystem(CosmoConditionalParamWGAN, params)\n",
    "dict_pickle_train = get_frechet_results_for_dataset(dataset_name=dataset_train_name, N=N)\n",
    "dict_pickle_full = dict(dict_pickle_train=dict_pickle_train, dict_pickle_test=dict_pickle_test, N=N)\n",
    "write_pickle('results_fid.pkl', dict_pickle_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regressor_contours(params, pred_params):\n",
    "    from plotting.triangle_marginals import contour_cl\n",
    "    npar = len(params)\n",
    "    nx, ny = 1, 1; fig, ax = plt.subplots(nx, ny, figsize=(ny * 6, nx * 4), squeeze=False, gridspec_kw={'wspace':0.0, 'hspace':0.0}); axc=ax[0,0]; axl=ax[0,:];\n",
    "    i=0\n",
    "    dict_ranges={'omega_m':lim_omega_m, 'sigma_8':lim_sigma_8}\n",
    "    columns=['omega_m', 'sigma_8']\n",
    "    kde_kwargs = {'n_points':50}\n",
    "    kw_contourf = {'alpha':0.05}\n",
    "    for i in range(npar):\n",
    "\n",
    "            dp = {'omega_m':pred_params[i, 0, :, 0], 'sigma_8':pred_params[i, 0, :, 1]}\n",
    "            contour_cl(axc, data=dp, ranges=dict_ranges, columns=columns, i=1, j=0, fill=True, color='b', kde_kwargs=kde_kwargs, kw_contourf=kw_contourf)\n",
    "            dp = {'omega_m':pred_params[i, 1, :, 0], 'sigma_8':pred_params[i, 1, :, 1]}\n",
    "            contour_cl(axc, data=dp, ranges=dict_ranges, columns=columns, i=1, j=0, fill=True, color='r', kde_kwargs=kde_kwargs, kw_contourf=kw_contourf)\n",
    "            axc.scatter(params[i,0], params[i,1], marker='*', s=200, c='k')\n",
    "\n",
    "    axc.grid(True)\n",
    "    axc.set(xlim=lim_omega_m, ylim=lim_sigma_8)\n",
    "    axc.set_ylabel(r'$\\sigma_8$', fontsize=fontsize_label)\n",
    "    axc.set_xlabel(r'$\\Omega_m$', fontsize=fontsize_label)\n",
    "    return fig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcualte_fid(pred_params):\n",
    "    w = np.zeros(pred_params.shape[0])\n",
    "    for i in range(pred_params.shape[0]):\n",
    "        pred_real = pred_params[i, 0, :, :] \n",
    "        pred_fake = pred_params[i, 1, :, :] \n",
    "        mean_real, cov_real = np.mean(pred_real, axis=0), np.cov(pred_real.T)\n",
    "        mean_fake, cov_fake = np.mean(pred_fake, axis=0), np.cov(pred_fake.T)\n",
    "        print(cov_real, cov_fake)\n",
    "        w[i] = wasserstein(mu1=mean_real, mu2=mean_fake, sig1=cov_real, sig2=cov_fake)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_regression = read_pickle('results_fid.pkl')\n",
    "params_pred_all = np.concatenate([dict_regression['dict_pickle_train']['pred_params'], dict_regression['dict_pickle_test']['pred_params']])\n",
    "params_all =np.concatenate([dict_regression['dict_pickle_train']['params'], dict_regression['dict_pickle_test']['params']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx, ny = 1, 1; fig, ax = plt.subplots(nx, ny, figsize=(ny * 8, nx * 6), squeeze=False); axc=ax[0,0]; axl=ax[0,:];\n",
    "axc.hist(dict_regression['dict_pickle_train']['pred_params'][1,0,:,0], bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.1\n",
    "lim_omega_m=[0.08, 0.52]\n",
    "lim_sigma_8=[0.4, 1.4]\n",
    "fontsize_label=16\n",
    "kw_scatter = {'alpha':0.1, 's':10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_regressor_contours(dict_regression['dict_pickle_test']['params'], dict_regression['dict_pickle_test']['pred_params']);\n",
    "fig.savefig('figure_regression.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcualte_fid(dict_regression['dict_pickle_train']['pred_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
