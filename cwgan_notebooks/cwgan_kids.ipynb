{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from moviepy.editor import VideoClip\n",
    "from moviepy.video.io.bindings import mplfig_to_npimage\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from gantools import utils\n",
    "from gantools import plot\n",
    "from gantools.gansystem import GANsystem\n",
    "from gantools.data import Dataset, Dataset_parameters\n",
    "from gantools.data import transformation\n",
    "\n",
    "from cosmotools.model import CosmoWGAN\n",
    "from cosmotools.metric import evaluation\n",
    "from cosmotools.data import load\n",
    "from cosmotools.utils import histogram_large\n",
    "\n",
    "from gantools.model import ConditionalParamWGAN\n",
    "from gantools.gansystem import GANsystem\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = 128 # Resolution of the image\n",
    "try_resume = True # Try to resume previous simulation\n",
    "\n",
    "def non_lin(x):\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_shuffled_name = 'kids_train_shuffled.h5'\n",
    "dataset_train_name = 'kids_train.h5'\n",
    "dataset_test_name = 'kids_test.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load.load_params_dataset(filename=dataset_train_shuffled_name, batch=2000, shape=[ns, ns], transform=transformation.random_transpose_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the histogram of the pixel densities after the forward map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vmin, vmax = utils.find_minmax(dataset)\n",
    "vmin, vmax = (0.006971482983495468, 1.3119225229919165)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histo, x = histogram_large(dataset, lim=(vmin, vmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_histogram(x, histo)\n",
    "print('min: {}'.format(vmin))\n",
    "print('max: {}'.format(vmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change maximum value for better plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmax = 0.125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot 16 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=4, ncols=4, figsize=(15,15))\n",
    "idx = 0\n",
    "imgs = dataset.get_samples(N=16)[0]\n",
    "params = dataset.get_samples(N=16)[1]\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        plot.plot_img(imgs[idx, :, :, 0], vmin=vmin, vmax=vmax, ax=col)\n",
    "        col.axis('off')\n",
    "        col.set_title('$\\Omega_M: $' + str(params[idx, 0]) + ', $\\sigma_8$: ' + str(params[idx, 1]), fontsize=14)\n",
    "        idx = idx + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters for the WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_str = '2D'\n",
    "global_path = '../saved_results'\n",
    "\n",
    "name = 'KidsConditional{}'.format(ns) + '_smart_' + time_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = False\n",
    "\n",
    "params_discriminator = dict()\n",
    "params_discriminator['stride'] = [1, 2, 2, 2, 2]\n",
    "params_discriminator['nfilter'] = [32, 64, 128, 256, 512]\n",
    "params_discriminator['shape'] = [[7, 7], [5, 5], [5, 5], [5,5], [3,3]]\n",
    "params_discriminator['batch_norm'] = [bn, bn, bn, bn, bn]\n",
    "params_discriminator['full'] = [512, 256, 128]\n",
    "params_discriminator['minibatch_reg'] = False\n",
    "params_discriminator['summary'] = True\n",
    "params_discriminator['data_size'] = 2\n",
    "\n",
    "params_generator = dict()\n",
    "params_generator['stride'] = [2, 2, 2, 2, 1]\n",
    "params_generator['latent_dim'] = 64\n",
    "params_generator['nfilter'] = [256, 128, 64, 32, 1]\n",
    "params_generator['shape'] = [[3, 3], [5, 5], [5, 5], [5, 5], [7,7]]\n",
    "params_generator['batch_norm'] = [bn, bn, bn, bn]\n",
    "params_generator['full'] = [256, 512, 8 * 8 * 512]\n",
    "params_generator['summary'] = True\n",
    "params_generator['non_lin'] = non_lin\n",
    "params_generator['data_size'] = 2\n",
    "\n",
    "params_optimization = dict()\n",
    "params_optimization['optimizer'] = 'rmsprop'\n",
    "params_optimization['batch_size'] = 64\n",
    "params_optimization['learning_rate'] = 1e-5\n",
    "params_optimization['epoch'] = 10\n",
    "\n",
    "# all parameters\n",
    "params = dict()\n",
    "params['net'] = dict() # All the parameters for the model\n",
    "params['net']['generator'] = params_generator\n",
    "params['net']['discriminator'] = params_discriminator\n",
    "params['net']['shape'] = [ns, ns, 1] # Shape of the image\n",
    "params['net']['gamma_gp'] = 10 # Gradient penalty\n",
    "\n",
    "# Conditional params\n",
    "params['net']['prior_normalization'] = False\n",
    "params['net']['cond_params'] = 2\n",
    "params['net']['init_range'] = [[0.101, 0.487], [0.487, 1.331]]\n",
    "params['net']['prior_distribution'] = \"gaussian_length\"\n",
    "params['net']['final_range'] = [0.1*np.sqrt(params_generator['latent_dim']), 1*np.sqrt(params_generator['latent_dim'])]\n",
    "\n",
    "params['optimization'] = params_optimization\n",
    "params['optimization']['discriminator'] = deepcopy(params_optimization)\n",
    "params['optimization']['generator'] = deepcopy(params_optimization)\n",
    "params['summary_every'] = 5000 # Tensorboard summaries every ** iterations\n",
    "params['print_every'] = 2500 # Console summaries every ** iterations\n",
    "params['save_every'] = 25000 # Save the model every ** iterations\n",
    "params['duality_every'] = 5\n",
    "params['summary_dir'] = os.path.join(global_path, name +'_summary/')\n",
    "params['save_dir'] = os.path.join(global_path, name + '_checkpoints/')\n",
    "params['Nstats'] = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume, params = utils.test_resume(try_resume, params)\n",
    "# If a model is reloaded and some parameters have to be changed, then it should be done here.\n",
    "# For example, setting the number of epoch to 5 would be:\n",
    "# params['optimization']['epoch'] = 5\n",
    "params['summary_dir'] = os.path.join(global_path, name +'_summary/')\n",
    "params['save_dir'] = os.path.join(global_path, name + '_checkpoints/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosmoConditionalParamWGAN(ConditionalParamWGAN, CosmoWGAN):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan = GANsystem(CosmoConditionalParamWGAN, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan.train(dataset, resume=resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 349163\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = 4\n",
    "\n",
    "# Generate grid\n",
    "# Note: pay attention that parameters should be inside the grid or at least colse to boundaries\n",
    "grid = []\n",
    "for c in range(wgan.net.params['cond_params']):\n",
    "    if c == 0:\n",
    "        gen_params = np.linspace(0.15, 0.4, inter)\n",
    "    if c == 1:\n",
    "        gen_params = np.linspace(0.6, 1.0, inter)\n",
    "    grid.append(gen_params)\n",
    "\n",
    "# Note: assume 2D grid of parameters\n",
    "gen_params = []\n",
    "for i in range(inter):\n",
    "    for j in range(inter):\n",
    "        gen_params.append([grid[0][i], grid[1][j]])\n",
    "gen_params = np.array(gen_params)\n",
    "\n",
    "# Produce images\n",
    "latent = wgan.net.sample_latent(bs=inter * inter, params=gen_params)\n",
    "gen_images = wgan.generate(N=inter * inter, **{'z': latent}, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a few fake samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=4, ncols=4, figsize=(15,15))\n",
    "idx = 0\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        plot.plot_img(gen_images[idx], vmin=vmin, vmax=vmax, ax=col)\n",
    "        col.set_title(\"$\\Omega_M$: \" + str(gen_params[idx][0])[0:7] + \", $\\sigma_8$: \" + str(gen_params[idx][1])[0:7], fontsize=14)\n",
    "        idx = idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare real and fake\n",
    "grid = np.array([[0.137, 1.23], [0.199, 0.87], [0.311, 0.842], [0.487, 0.643]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load.load_params_dataset(filename=dataset_test_name, batch=10, sorted=True, shape=[ns, ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce images\n",
    "latent = wgan.net.sample_latent(bs=len(grid), params=grid)\n",
    "gen_images = wgan.generate(N=len(grid), **{'z': latent}, checkpoint=checkpoint)\n",
    "\n",
    "# Get real images\n",
    "real_images = []\n",
    "for p in grid:\n",
    "    real_images.append(dataset.get_data_for_params(p, N=10)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=4, figsize=(15, 7.5))\n",
    "idx = 0\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        if idx < 4:\n",
    "            plot.plot_img(gen_images[idx], vmin=vmin, vmax=vmax, ax=col)\n",
    "        else:\n",
    "            plot.plot_img(real_images[idx % 4][np.random.randint(10)], vmin=vmin, vmax=vmax, ax=col)\n",
    "        col.set_title(\"$\\Omega_M$: \" + str(grid[idx%4][0]) + \", $\\sigma_8$: \" + str(grid[idx%4][1]), fontsize=14)\n",
    "        idx = idx + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = wgan.net.sample_latent(params=np.array([[0.171, 0.976]]))\n",
    "gen_sample = wgan.generate(N=1, **{'z': latent}, checkpoint=checkpoint)\n",
    "plot.plot_img(gen_sample[0], vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate grid\n",
    "grid = []\n",
    "for c in range(wgan.net.params['cond_params']):\n",
    "    if c == 0:\n",
    "        gen_params = np.linspace(0.2, 0.3, inter)\n",
    "    if c == 1:\n",
    "        gen_params = np.linspace(0.60, 0.9, inter)\n",
    "    grid.append(gen_params)\n",
    "\n",
    "# Note: assume 2D grid of parameters\n",
    "gen_params = []\n",
    "for i in range(inter):\n",
    "    for j in range(inter):\n",
    "        gen_params.append([grid[0][i], grid[1][j]])\n",
    "gen_params = np.array(gen_params)\n",
    "\n",
    "imgs = evaluation.generate_samples_same_seed(wgan, gen_params, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=inter, ncols=inter, figsize=(15,15))\n",
    "idx = 0\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        plot.plot_img(imgs[idx][0], vmin=vmin, vmax=vmax, ax=col)\n",
    "        col.set_title(\"$\\Omega_M$: \" + str(gen_params[idx][0])[0:7] + \", $\\sigma_8$: \" + str(gen_params[idx][1])[0:7], fontsize=14)\n",
    "        idx = idx + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define path of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long traversal (back and forth)\n",
    "path = [[0.189, 0.659],\n",
    "        [0.212, 0.727],\n",
    "        [0.233, 0.791],\n",
    "        [0.254, 0.852],\n",
    "        [0.273, 0.91 ],\n",
    "        [0.292, 0.966],\n",
    "        [0.33,  0.898],\n",
    "        [0.311, 0.842],\n",
    "        [0.291, 0.783],\n",
    "        [0.271, 0.723],\n",
    "        [0.25, 0.658],\n",
    "        [0.227, 0.591],\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in path:\n",
    "    p.append(True)\n",
    "\n",
    "path = evaluation.interpolate_between(path, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate frames\n",
    "frames = evaluation.generate_samples_same_seed(wgan, path[:len(path)//2], checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "def make_frame(t):\n",
    "    t = int(t)\n",
    "    ax.clear()\n",
    "    plot.plot_img(frames[t][0], vmin=vmin, vmax=vmax, ax=ax)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(\"$\\Omega_M$: \" + str(path[t][0])[0:7] + \", $\\sigma_8$: \" + str(path[t][1])[0:7], fontsize=28)\n",
    "    return mplfig_to_npimage(fig)\n",
    "\n",
    "animation = VideoClip(make_frame, duration=len(path)//2)\n",
    "plt.close()\n",
    "animation.ipython_display(fps=20, loop=True, autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the sample quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load.load_params_dataset(filename=dataset_train_name, batch=N, sorted=True, shape=[ns, ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dataset.get_different_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define getter functions for every parameter set\n",
    "# Note this is needed to save memory, as in this way every subset is loaded only when needed\n",
    "real_imgs = []\n",
    "fake_imgs = []\n",
    "for p in params:\n",
    "    real_imgs.append(lambda p1=p: dataset.get_data_for_params(p1, N=N)[0])\n",
    "    fake_imgs.append(lambda p1=p: evaluation.generate_samples_params(wgan, p1, nsamples=N, checkpoint=checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters used for plotting\n",
    "lenstools = True\n",
    "def title_func(params):\n",
    "    return \"$\\Omega_M$: \" + str(params[0])[0:7] + \", $\\sigma_8$: \" + str(params[1])[0:7]\n",
    "\n",
    "if lenstools:\n",
    "    ylims = [[(1e-7, 1e-3), (0, 0.5)], [(1e-2, 1e3), (0, 0.5)], [(1e-2, 1e5), (0, 0.5)]]\n",
    "else:\n",
    "    ylims = [[(1e-4, 2e0), (0, 0.5)], [(1e-2, 1e3), (0, 0.5)], [(1e-2, 1e5), (0, 0.5)]]\n",
    "fractional_difference = [True, True, True]\n",
    "\n",
    "box_l = (5*np.pi/180)\n",
    "bin_k = 50\n",
    "cut = [200, 6000]\n",
    "cut_corr = [0, 6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, score = evaluation.compute_plots_for_params(params, real_imgs, fake_imgs, param_str=title_func, log=False, lim=(0, 0.4), ylims=ylims, confidence='std', fractional_difference=fractional_difference, cut=cut, lenstools=lenstools, box_l=box_l, bin_k=bin_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score has shape n_params, n_stats, losses\n",
    "print(\"PSD score:\", score[:, 0, 0])\n",
    "print(\"Peak score:\", score[:, 1, 0])\n",
    "print(\"Mass score:\", score[:, 2, 0])\n",
    "print(\"PSD diff:\", score[:, 0, 1])\n",
    "\n",
    "print(\"PSD total:\", np.mean(score[:, 0, 0]), \" +/- \", np.std(score[:, 0, 0]))\n",
    "print(\"Peak total:\", np.mean(score[:, 1, 0]), \" +/- \", np.std(score[:, 1, 0]))\n",
    "print(\"Mass total:\", np.mean(score[:, 2, 0]), \" +/- \", np.std(score[:, 2, 0]))\n",
    "print(\"PSD diff total:\", np.mean(score[:, 2, 1]), \" +/- \", np.std(score[:, 2, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scores for heatmap\n",
    "train_scores = score\n",
    "train_params = params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr, k = evaluation.compute_correlations(real_imgs, fake_imgs, params, cut=cut_corr, lenstools=lenstools, box_l=box_l, bin_k=bin_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_c = evaluation.plot_correlations(corr, k, params, tick_every=10, param_str=title_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correlation losses:\", score_c.flatten())\n",
    "print(\"Total correlation loss:\", np.mean(score_c), \" +/- \", np.std(score_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MS-SSIM score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_fake, s_real = evaluation.compute_ssim_score(fake_imgs, real_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(s_fake)\n",
    "print(s_real)\n",
    "print(np.mean(s_fake), \" +/- \", np.std(s_fake))\n",
    "print(np.mean(s_real), \" +/- \", np.std(s_real))\n",
    "print(np.mean(np.abs(s_fake - s_real)), \" +/- \", np.std(np.abs(s_fake - s_real)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load.load_params_dataset(filename=dataset_train_shuffled_name, batch=N, shape=[ns, ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_imgs, params = dataset.get_samples(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_imgs = evaluation.generate_samples_params(wgan, params, nsamples=N, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_fake, s_real = evaluation.compute_ssim_score([fake_imgs], [real_imgs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s_fake[0])\n",
    "print(s_real[0])\n",
    "print(np.abs(s_fake[0] - s_real[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load.load_params_dataset(filename=dataset_test_name, batch=N, sorted=True, shape=[ns, ns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_inter = [[0.137, 1.23],\n",
    "               [0.25, 0.658],\n",
    "               [0.311, 0.842],\n",
    "               [0.199, 0.87],\n",
    "               [0.254, 0.852],\n",
    "               [0.312, 0.664],\n",
    "               [0.356, 0.614],\n",
    "               [0.421, 0.628]]\n",
    "params_inter = np.array(params_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define getter functions for every parameter set\n",
    "# Note this is needed to save memory, as in this way every subset is loaded only when needed\n",
    "real_imgs = []\n",
    "fake_imgs = []\n",
    "for p in params_inter:\n",
    "    real_imgs.append(lambda p1=p: dataset.get_data_for_params(p1, N=N)[0])\n",
    "    fake_imgs.append(lambda p1=p: evaluation.generate_samples_params(wgan, p1, nsamples=N, checkpoint=checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, score_inter = evaluation.compute_plots_for_params(params_inter, real_imgs, fake_imgs, param_str=title_func, ylims=ylims, log=False, confidence='std', lim=(0, 0.4), fractional_difference=fractional_difference, lenstools=lenstools, cut=cut, box_l=box_l, bin_k=bin_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PSD score:\", score_inter[:, 0, 0])\n",
    "print(\"Peak score:\", score_inter[:, 1, 0])\n",
    "print(\"Mass score:\", score_inter[:, 2, 0])\n",
    "print(\"PSD diff:\", score_inter[:, 0, 1])\n",
    "\n",
    "print(\"PSD total:\", np.mean(score_inter[:, 0, 0]), \" +/- \", np.std(score_inter[:, 0, 0]))\n",
    "print(\"Peak total:\", np.mean(score_inter[:, 1, 0]), \" +/- \", np.std(score_inter[:, 1, 0]))\n",
    "print(\"Mass total:\", np.mean(score_inter[:, 2, 0]), \" +/- \", np.std(score_inter[:, 2, 0]))\n",
    "print(\"PSD diff total:\", np.mean(score_inter[:, 2, 1]), \" +/- \", np.std(score_inter[:, 2, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr, k = evaluation.compute_correlations(real_imgs, fake_imgs, params_inter, cut=cut_corr, lenstools=lenstools, box_l=box_l, bin_k=bin_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_c_inter = evaluation.plot_correlations(corr, k, params_inter, tick_every=10, param_str=title_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correlation losses:\", score_c_inter.flatten())\n",
    "print(\"Total correlation loss:\", np.mean(score_c_inter), \" +/- \", np.std(score_c_inter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrapolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_extra = [[0.196, 1.225],\n",
    "                [0.127, 0.836],\n",
    "                [0.487, 0.643]]\n",
    "params_extra = np.array(params_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define getter functions for every parameter set\n",
    "# Note this is needed to save memory, as in this way every subset is loaded only when needed\n",
    "real_imgs = []\n",
    "fake_imgs = []\n",
    "for p in params_extra:\n",
    "    real_imgs.append(lambda p1=p: dataset.get_data_for_params(p1, N=N)[0])\n",
    "    fake_imgs.append(lambda p1=p: evaluation.generate_samples_params(wgan, p1, nsamples=N, checkpoint=checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, score_extra = evaluation.compute_plots_for_params(params_extra, real_imgs, fake_imgs, param_str=title_func, ylims=ylims, log=False, confidence='std', lim=(0, 0.4), fractional_difference=fractional_difference, lenstools=lenstools, cut=cut, box_l=box_l, bin_k=bin_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PSD score:\", score_inter[:, 0, 0])\n",
    "print(\"Peak score:\", score_inter[:, 1, 0])\n",
    "print(\"Mass score:\", score_inter[:, 2, 0])\n",
    "print(\"PSD diff:\", score_inter[:, 0, 1])\n",
    "\n",
    "print(\"PSD total:\", np.mean(score_inter[:, 0, 0]), \" +/- \", np.std(score_inter[:, 0, 0]))\n",
    "print(\"Peak total:\", np.mean(score_inter[:, 1, 0]), \" +/- \", np.std(score_inter[:, 1, 0]))\n",
    "print(\"Mass total:\", np.mean(score_inter[:, 2, 0]), \" +/- \", np.std(score_inter[:, 2, 0]))\n",
    "print(\"PSD diff total:\", np.mean(score_inter[:, 2, 1]), \" +/- \", np.std(score_inter[:, 2, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, k = evaluation.compute_correlations(real_imgs, fake_imgs, params_extra, cut=cut_corr, lenstools=lenstools, box_l=box_l, bin_k=bin_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_c_extra = evaluation.plot_correlations(corr, k, params_extra, tick_every=10, param_str=title_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correlation losses:\", score_c_extra.flatten())\n",
    "print(\"Total correlation loss:\", np.mean(score_c_extra), \" +/- \", np.std(score_c_extra))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = np.vstack([params_inter, params_extra])\n",
    "test_scores = np.vstack([score_inter, score_extra])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_heatmap(test_scores[:, 0, 1], test_params, train_scores[:, 0, 1], train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.025, 0.05, 0.10, 0.15]\n",
    "plot.plot_heatmap(test_scores[:, 0, 1], test_params, train_scores[:, 0, 1], train_params, thresholds=thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = np.vstack([params_inter, params_extra])\n",
    "test_c_scores = np.vstack([score_c_inter, score_c_extra])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_heatmap(test_c_scores[:, 0], test_params, score_c[:, 0], train_params, vmax=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MS-SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load.load_params_dataset(filename=dataset_test_name, batch=N, sorted=True, shape=[ns, ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define getter functions for every parameter set\n",
    "# Note this is needed to save memory, as in this way every subset is loaded only when needed\n",
    "real_imgs = []\n",
    "fake_imgs = []\n",
    "for p in dataset.get_different_params():\n",
    "    real_imgs.append(lambda p1=p: dataset.get_data_for_params(p1, N=N)[0])\n",
    "    fake_imgs.append(lambda p1=p: evaluation.generate_samples_params(wgan, p1, nsamples=N, checkpoint=checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_fake, s_real = evaluation.compute_ssim_score(fake_imgs, real_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(s_fake)\n",
    "print(s_real)\n",
    "print(np.mean(s_fake), \" +/- \", np.std(s_fake))\n",
    "print(np.mean(s_real), \" +/- \", np.std(s_real))\n",
    "print(np.mean(np.abs(s_fake - s_real)), \" +/- \", np.std(np.abs(s_fake - s_real)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_imgs, params = dataset.get_random_data(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_imgs = evaluation.generate_samples_params(wgan, params, nsamples=N, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_fake, s_real = evaluation.compute_ssim_score([fake_imgs], [real_imgs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s_fake[0])\n",
    "print(s_real[0])\n",
    "print(np.abs(s_fake[0] - s_real[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = load.load_params_dataset(filename=dataset_train_name, batch=N, sorted=True)\n",
    "dataset_test = load.load_params_dataset(filename=dataset_test_name, batch=N, sorted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_data(params):\n",
    "    try:\n",
    "        data = dataset_train.get_data_for_params(params, N)[0].reshape((N, ns, ns))\n",
    "    except:\n",
    "        data = dataset_test.get_data_for_params(params, N)[0].reshape((N, ns, ns))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of dictionaries for video generation\n",
    "X = []\n",
    "for i in range(len(path)):\n",
    "    X.append({})\n",
    "    X[i]['params'] = np.array([path[i][0], path[i][1]])\n",
    "    X[i]['real'] = None\n",
    "    X[i]['fake'] = lambda p=X[i]['params']: evaluation.generate_samples_params(wgan, p, nsamples=N, checkpoint=checkpoint)[:, :, :, 0]\n",
    "    if path[i][2]:\n",
    "        X[i]['real'] = lambda p=X[i]['params']: load_real_data(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dataset_train.get_different_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate frames\n",
    "frames = evaluation.make_frames(X, title_func=title_func, log=False, confidence='std', lim=(0, 0.4), vmin=vmin, vmax=vmax, params_grid=param_grid, fractional_difference=fractional_difference, ylims=ylims, cut=cut, lenstools=lenstools, save_frames_dir='frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate video\n",
    "d_frame = 0.75\n",
    "duration = len(X) * d_frame\n",
    "animation = VideoClip(evaluation.make_frame_func(X, 'frames', duration, frames_stat=3), duration=duration)\n",
    "animation.ipython_display(fps=10, loop=True, autoplay=True, width=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity  checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load.load_params_dataset(filename=dataset_test_name, batch=nsamples, shape=[ns, ns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real images and real parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, parameters = dataset.get_samples(nsamples)\n",
    "dat = Dataset_parameters(images, parameters)\n",
    "it = dat.iter(nsamples)\n",
    "batch = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_out = wgan.get_values_at(batch, '_D_real', checkpoint=checkpoint)\n",
    "print(np.mean(disc_out), np.std(disc_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random images with real parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, parameters = dataset.get_samples(nsamples)\n",
    "images = np.random.rand(nsamples, ns, ns)\n",
    "dat = Dataset_parameters(images, parameters)\n",
    "it = dat.iter(nsamples)\n",
    "batch = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_out = wgan.get_values_at(batch, '_D_real', checkpoint=checkpoint)\n",
    "print(np.mean(disc_out), np.std(disc_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real images with fake parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, parameters = dataset.get_samples(nsamples)\n",
    "for c in range(wgan.net.params['cond_params']):\n",
    "    parameters[:, c] = utils.scale2range(np.random.rand(nsamples), [0, 1], wgan.net.params['init_range'][c])\n",
    "dat = Dataset_parameters(images, parameters)\n",
    "it = dat.iter(nsamples)\n",
    "batch = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_out = wgan.get_values_at(batch, '_D_real', checkpoint=checkpoint)\n",
    "print(np.mean(disc_out), np.std(disc_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random images with fake parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, parameters = dataset.get_samples(nsamples)\n",
    "images = np.random.rand(nsamples, ns, ns)\n",
    "for c in range(wgan.net.params['cond_params']):\n",
    "    parameters[:, c] = utils.scale2range(np.random.rand(nsamples), [0, 1], wgan.net.params['init_range'][c])\n",
    "dat = Dataset_parameters(images, parameters)\n",
    "it = dat.iter(nsamples)\n",
    "batch = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_out = wgan.get_values_at(batch, '_D_real', checkpoint=checkpoint)\n",
    "print(np.mean(disc_out), np.std(disc_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosmotools.metric import feature_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_func(params):\n",
    "    return \"$\\Omega_M$: \" + str(params[0])[0:7] + \", $\\sigma_8$: \" + str(params[1])[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = load.load_params_dataset(filename=dataset_train_name, batch=N, sorted=True, shape=[ns, ns])\n",
    "dataset_test = load.load_params_dataset(filename=dataset_test_name, batch=N, sorted=True, shape=[ns, ns])\n",
    "\n",
    "def batch_loader(params):\n",
    "    try:\n",
    "        dat = dataset_train.get_data_for_params(params, nsamples)\n",
    "    except:\n",
    "        dat = dataset_test.get_data_for_params(params, nsamples)\n",
    "    images, parameters = dat\n",
    "    dataset = Dataset_parameters(images.reshape((nsamples, ns, ns)), parameters)\n",
    "    it = dataset.iter(nsamples)\n",
    "    batch = next(it)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long traversal (back and forth)\n",
    "path = [[0.189, 0.659],\n",
    "        [0.212, 0.727],\n",
    "        [0.233, 0.791],\n",
    "        [0.254, 0.852],\n",
    "        [0.273, 0.91 ],\n",
    "        [0.292, 0.966],\n",
    "        [0.33,  0.898],\n",
    "        [0.311, 0.842],\n",
    "        [0.291, 0.783],\n",
    "        [0.271, 0.723],\n",
    "        [0.25, 0.658],\n",
    "        [0.227, 0.591],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define params grid\n",
    "diff_params = np.array(path)\n",
    "d_frame = 1\n",
    "duration = len(diff_params) * d_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generator\n",
    "generator = False\n",
    "make_frames_feat, make_frames_weig = feature_analysis.make_features_videos(wgan, batch_loader, diff_params, duration, title_func=title_func, checkpoint=checkpoint, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = VideoClip(make_frames_feat, duration=duration)\n",
    "animation.ipython_display(fps=10, loop=True, autoplay=True, width=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = VideoClip(make_frames_weig, duration=duration)\n",
    "animation.ipython_display(fps=10, loop=True, autoplay=True, width=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generator\n",
    "generator = True\n",
    "make_frames_feat, make_frames_weig = feature_analysis.make_features_videos(wgan, batch_loader, diff_params, duration, title_func=title_func, checkpoint=checkpoint, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = VideoClip(make_frames_feat, duration=duration)\n",
    "animation.ipython_display(fps=10, loop=True, autoplay=True, width=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = VideoClip(make_frames_weig, duration=duration)\n",
    "animation.ipython_display(fps=10, loop=True, autoplay=True, width=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results for one cosmology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.array([0.254, 0.852])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load.load_params_dataset(filename=dataset_test_name, batch=N, sorted=True, shape=[ns, ns])\n",
    "raw_images = dataset.get_data_for_params(p, N=N)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sample_raw = evaluation.generate_samples_params(wgan, p, nsamples=N, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.compute_and_plot_psd(raw_images, gen_sample_raw, multiply=True, confidence='std', fractional_difference=True, lenstools=lenstools, box_l=box_l, bin_k=bin_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "_ = evaluation.plot_stats(ax, gen_sample_raw, raw_images, log=False, lim=(0,0.4), confidence='std', multiply=True, fractional_difference=[True, True, True], lenstools=lenstools, box_l=box_l, bin_k=bin_k)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_r, c_f, _ = evaluation.compute_plot_correlation(raw_images, gen_sample_raw, cut=cut_corr, tick_every=10, lenstools=lenstools, box_l=box_l, bin_k=bin_k)\n",
    "print(np.linalg.norm(c_r-c_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.compute_plot_psd_mode_hists(raw_images, gen_sample_raw, modes=3, hist_batch=4, confidence='std', lenstools=lenstools, box_l=box_l, bin_k=bin_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = np.array([[0.332, 0.724], [0.37, 0.838], [0.425, 1], [0.487, 1.331]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load.load_params_dataset(filename=dataset_train_name, batch=N, sorted=True, shape=[ns, ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define getter functions for every parameter set\n",
    "# Note this is needed to save memory, as in this way every subset is loaded only when needed\n",
    "fake_imgs = []\n",
    "real_imgs = []\n",
    "for p in path:\n",
    "    if dataset.has_params(p):\n",
    "        real_imgs.append(lambda p1=p: dataset.get_data_for_params(p1, N=N)[0])\n",
    "    else:\n",
    "        real_imgs.append(None)\n",
    "    fake_imgs.append(lambda p1=p: evaluation.generate_samples_params(wgan, p1, nsamples=N, checkpoint=checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if lenstools:\n",
    "    ylims = [[(1e-7, 5e-3), (0, 0.5)], [(1e-2, 1e3), (0, 0.5)], [(1e-2, 1e5), (0, 0.5)]]\n",
    "else:\n",
    "    ylims = [[(1e-4, 2e0), (0, 0.5)], [(1e-2, 1e3), (0, 0.5)], [(1e-2, 1e5), (0, 0.5)]]\n",
    "fig, score = evaluation.compute_plots_for_params(path, real_imgs, fake_imgs, param_str=title_func, log=False, lim=(0, 0.8), ylims=ylims, confidence='std', fractional_difference=fractional_difference, cut=cut, lenstools=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load.load_params_dataset(filename=dataset_train_name, batch=N, sorted=True, shape=[ns, ns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worst correlation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_imgs = dataset.get_data_for_params(np.array([0.469, 0.589]), N=N)[0]\n",
    "fake_imgs = evaluation.generate_samples_params(wgan, np.array([0.469, 0.589]), nsamples=N, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_r, c_f, _ = evaluation.compute_plot_correlation(real_imgs, fake_imgs, cut=cut_corr, tick_every=10, lenstools=lenstools, box_l=box_l, bin_k=bin_k)\n",
    "print(np.linalg.norm(c_r - c_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.compute_and_plot_psd(real_imgs, fake_imgs, multiply=True, confidence='std', fractional_difference=True, lenstools=lenstools, box_l=box_l, bin_k=bin_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.compute_plot_psd_mode_hists(real_imgs, fake_imgs, modes=3, lenstools=lenstools, hist_batch=4, confidence='std', box_l=box_l, bin_k=bin_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best correlation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_imgs = dataset.get_data_for_params(np.array([0.148, 0.9]), N=N)[0]\n",
    "fake_imgs = evaluation.generate_samples_params(wgan, np.array([0.148, 0.9]), nsamples=N, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_r, c_f, _ = evaluation.compute_plot_correlation(real_imgs, fake_imgs, cut=cut_corr, tick_every=10, lenstools=lenstools, box_l=box_l, bin_k=bin_k)\n",
    "print(np.linalg.norm(c_r - c_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.compute_and_plot_psd(real_imgs, fake_imgs, multiply=True, confidence='std', fractional_difference=True, lenstools=lenstools, box_l=box_l, bin_k=bin_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluation.compute_plot_psd_mode_hists(real_imgs, fake_imgs, modes=3, lenstools=lenstools, hist_batch=4, confidence='std', box_l=box_l, bin_k=bin_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation of a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load.load_params_dataset(filename=dataset_train_shuffled_name, batch=N, shape=[ns, ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_imgs, params = dataset.get_samples(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_imgs = evaluation.generate_samples_params(wgan, params, nsamples=N, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_r, c_f, _ = evaluation.compute_plot_correlation(real_imgs, fake_imgs, cut=cut_corr, tick_every=10, lenstools=lenstools, box_l=box_l, bin_k=bin_k)\n",
    "print(np.linalg.norm(c_r - c_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.compute_and_plot_psd(real_imgs, fake_imgs, multiply=True, confidence='std', fractional_difference=True, lenstools=lenstools, box_l=box_l, bin_k=bin_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check smoothness of correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosmotools.metric import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load.load_params_dataset(filename=dataset_test_name, batch=N, sorted=True, shape=[ns, ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_test = dataset.get_different_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_test = []\n",
    "for p in params_test:\n",
    "    if lenstools:\n",
    "        c, _ = stats.psd_correlation_lenstools(dataset.get_data_for_params(p, N)[0], box_l=box_l, bin_k=bin_k, cut=cut_corr)\n",
    "    else:\n",
    "        c, _ = stats.psd_correlation(dataset.get_data_for_params(p, N)[0], box_l=box_l, bin_k=bin_k, log_sampling=False, cut=cut_corr)\n",
    "    corr_test.append(np.linalg.norm(c))\n",
    "corr_test = np.array(corr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load.load_params_dataset(filename=dataset_train_name, batch=N, sorted=True, shape=[ns, ns])\n",
    "params_train = dataset.get_different_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_train = []\n",
    "for p in params_train:\n",
    "    if lenstools:\n",
    "        c, _ = stats.psd_correlation_lenstools(dataset.get_data_for_params(p, N)[0], cut=cut_corr, box_l=box_l, bin_k=bin_k)\n",
    "    else:\n",
    "        c, _ = stats.psd_correlation(dataset.get_data_for_params(p, N)[0], box_l=box_l, bin_k=bin_k, log_sampling=False, cut=cut_corr)\n",
    "    corr_train.append(np.linalg.norm(c))\n",
    "corr_train = np.array(corr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = np.vstack([params_train, params_test])\n",
    "corr = np.hstack([corr_train, corr_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot.plot_heatmap(corr, params, vmax=corr.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frchet Inception distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load.load_params_dataset(filename=dataset_test_name, batch=N, sorted=True, shape=[ns, ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "# params = dataset.get_different_params()\n",
    "params = [[0.137, 1.23],\n",
    "          [0.25, 0.658],\n",
    "          [0.311, 0.842],\n",
    "          [0.199, 0.87],\n",
    "          [0.254, 0.852],\n",
    "          [0.312, 0.664],\n",
    "          [0.356, 0.614],\n",
    "          [0.421, 0.628]]\n",
    "params = np.array(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate images\n",
    "real_imgs = []\n",
    "fake_imgs = []\n",
    "for p in params:\n",
    "    real_imgs.append(dataset.get_data_for_params(p, N=N)[0])\n",
    "    fake_imgs.append(evaluation.generate_samples_params(wgan, p, nsamples=N, checkpoint=checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load regressor\n",
    "regressor_path = '../saved_results/Regressor/Kids_Regressor_128_smart_2D_mac_checkpoints/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fids, fig = evaluation.compute_plot_fid(real_imgs, fake_imgs, params, regressor_path, batch_size=250, checkpoint=140000, lims=[[0.05, 0.5], [0.4, 1.4]], alpha=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fids)\n",
    "print(np.mean(fids), \"+/-\", np.std(fids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
