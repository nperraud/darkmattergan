{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.insert(0, '../')\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from gantools import data\n",
    "from gantools import utils\n",
    "from gantools import plot\n",
    "from gantools.model import WGAN, CosmoWGAN\n",
    "from gantools.gansystem import GANsystem, PaulinaGANsystem\n",
    "from gantools.data import fmap\n",
    "from gantools import evaluation\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = 32 # Resolution of the image\n",
    "try_resume = False # Try to resume previous simulation\n",
    "Mpch = 70 # Type of dataset (select 70 or 350)\n",
    "\n",
    "# Do not change these for now\n",
    "shift = 3\n",
    "c = 40000\n",
    "forward = functools.partial(fmap.stat_forward, shift=shift, c=c)\n",
    "backward = functools.partial(fmap.stat_backward, shift=shift, c=c)\n",
    "def non_lin(x):\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.load.load_dataset(nsamples=10, spix=ns, Mpch=Mpch, forward_map=forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset can return an iterator.\n",
    "it = dataset.iter(10)\n",
    "print(next(it).shape)\n",
    "del it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the data\n",
    "X = dataset.get_all_data().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the backward maps invert the forward map.\n",
    "assert(np.sum(np.abs(forward(backward(X))-X))< 1)\n",
    "# # For debugging\n",
    "# np.sum(np.abs(forward(backward(X))-X))\n",
    "# forward(backward(X))-X\n",
    "# x = np.arange(1e4)\n",
    "# plt.plot(x, backward(forward(x))-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the histogram of the pixel densities after the forward map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X, 100)\n",
    "print('min: {}'.format(np.min(X)))\n",
    "print('max: {}'.format(np.max(X)))\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to free some memory\n",
    "del X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot 16 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plot.draw_images(dataset.get_samples(N=16),nx=4,ny=4);\n",
    "plt.title(\"Real samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters for the WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_str = '2D_paulina_tradgan4'\n",
    "global_path = 'saved_results'\n",
    "\n",
    "name = 'WGAN{}'.format(ns) + '_' + time_str\n",
    "\n",
    "# Here I use>\n",
    "# self.disc_loss_calc2 = tf.reduce_mean(self.plc_float_r - self.plc_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = False\n",
    "\n",
    "# Parameters for the discriminator\n",
    "params_discriminator = dict()\n",
    "params_discriminator['stride'] = [2, 2, 2, 1]\n",
    "params_discriminator['nfilter'] = [16, 64, 256, 32]\n",
    "params_discriminator['shape'] = [[5, 5],[5, 5], [5, 5], [3, 3]]\n",
    "params_discriminator['batch_norm'] = [bn, bn, bn, bn]\n",
    "params_discriminator['full'] = [32]\n",
    "params_discriminator['minibatch_reg'] = False\n",
    "params_discriminator['summary'] = True\n",
    "params_discriminator['is_3d'] = False\n",
    "\n",
    "# Parameters for the generator\n",
    "params_generator = dict()\n",
    "params_generator['stride'] = [1, 1, 2, 1, 1]\n",
    "params_generator['latent_dim'] = 16*16*32\n",
    "params_generator['nfilter'] = [32, 64, 256, 32, 1]\n",
    "params_generator['shape'] = [[5, 5], [5, 5],[5, 5], [5, 5], [5, 5]]\n",
    "params_generator['batch_norm'] = [bn, bn, bn, bn]\n",
    "params_generator['full'] = []\n",
    "params_generator['summary'] = True\n",
    "params_generator['non_lin'] = non_lin\n",
    "params_generator['is_3d'] = False\n",
    "\n",
    "# Optimization parameters\n",
    "d_opt = dict()\n",
    "d_opt['optimizer'] = \"rmsprop\"\n",
    "d_opt['learning_rate'] = 3e-5\n",
    "d_opt['kwargs'] = dict()\n",
    "params_optimization = dict()\n",
    "params_optimization['batch_size'] = 16\n",
    "params_optimization['epoch'] = 10\n",
    "params_optimization['discriminator'] = deepcopy(d_opt)\n",
    "params_optimization['generator'] = deepcopy(d_opt)\n",
    "params_optimization['n_critic'] = 5\n",
    "\n",
    "\n",
    "# Cosmology parameters\n",
    "params_cosmology = dict()\n",
    "params_cosmology['forward_map'] = forward\n",
    "params_cosmology['backward_map'] = backward\n",
    "\n",
    "# all parameters\n",
    "params = dict()\n",
    "params['net'] = dict() # All the parameters for the model\n",
    "params['net']['generator'] = params_generator\n",
    "params['net']['discriminator'] = params_discriminator\n",
    "params['net']['cosmology'] = params_cosmology # Parameters for the cosmological summaries\n",
    "params['net']['prior_distribution'] = 'gaussian'\n",
    "params['net']['shape'] = [ns, ns, 1] # Shape of the image\n",
    "params['net']['is_3d'] = False\n",
    "params['net']['gamma_gp'] = 10 # Gradient penalty\n",
    "\n",
    "params['optimization'] = params_optimization\n",
    "params['summary_every'] = 200 # Tensorboard summaries every ** iterations\n",
    "params['print_every'] = 50 # Console summaries every ** iterations\n",
    "params['save_every'] = 1000 # Save the model every ** iterations\n",
    "params['summary_dir'] = os.path.join(global_path, name +'_summary/')\n",
    "params['save_dir'] = os.path.join(global_path, name + '_checkpoints/')\n",
    "params['Nstats'] = 2000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume, params = utils.test_resume(try_resume, params)\n",
    "# If a model is reloaded and some parameters have to be changed, then it should be done here.\n",
    "# For example, setting the number of epoch to 5 would be:\n",
    "params['optimization']['epoch'] = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wgan = PaulinaGANsystem(CosmoWGAN, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wgan.train(dataset, resume=resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate new samples\n",
    "To have meaningful statistics, be sure to generate enough samples\n",
    "* 2000 : 32 x 32\n",
    "* 500 : 64 x 64\n",
    "* 200 : 128 x 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2000 # Number of samples\n",
    "gen_sample = np.squeeze(wgan.generate(N=N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a few fake samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plot.draw_images(gen_sample,nx=4,ny=4);\n",
    "plt.title(\"Fake samples\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the sample quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before computing the statistics, we need to invert the mapping\n",
    "raw_images = backward(dataset.get_samples(dataset.N))\n",
    "gen_sample_raw = backward(gen_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logel2, l2, logel1, l1 = evaluation.compute_and_plot_psd(raw_images, gen_sample_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logel2, l2, logel1, l1 = evaluation.compute_and_plot_peak_cout(raw_images, gen_sample_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logel2, l2, logel1, l1 = evaluation.compute_and_plot_mass_hist(raw_images, gen_sample_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a single metric number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gantools.metric import ganlist\n",
    "single_metric = ganlist.global_score(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The global metric is {}\".format(single_metric(raw_images, gen_sample_raw)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the curves from the summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathfig = 'figures/'\n",
    "os.makedirs(pathfig, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from shutil import copy\n",
    "\n",
    "\n",
    "\n",
    "def get_event_data(event_files, tag, selec_it=None):\n",
    "    data = []\n",
    "    it = []\n",
    "    if selec_it:\n",
    "        selec_it = set(selec_it)\n",
    "    for path_event in event_files:\n",
    "        try:\n",
    "            for e in tf.train.summary_iterator(path_event):\n",
    "                for v in e.summary.value:\n",
    "                    if tag in v.tag:\n",
    "                        if selec_it is None or e.step in selec_it:\n",
    "                            data.append(v.simple_value)\n",
    "                            it.append(e.step)\n",
    "        except:\n",
    "            print('Warning corrupted file')\n",
    "    return np.array(data), np.array(it)\n",
    "\n",
    "\n",
    "def get_event_files(summary_dir):\n",
    "    # Getting the event file\n",
    "    event_files = []\n",
    "    for filename in os.listdir(summary_dir):\n",
    "        if 'events.out.tfevents' in filename:\n",
    "            event_files.append(os.path.join(summary_dir, filename))\n",
    "    # if len(event_files)>1:\n",
    "    #     raise ValueError('Multiple event files')\n",
    "    if len(event_files) == 0:\n",
    "        raise ValueError('No event files')\n",
    "    return event_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary_dir = wgan.params['summary_dir']\n",
    "event_files = get_event_files(summary_dir)\n",
    "maxit = 30000\n",
    "selec_it = set(range(maxit+1))\n",
    "\n",
    "selec = [1,2,3,5,6,7]\n",
    "measures_list = ['final/global_score_1',\n",
    "                 'final/mass_histogram_l2_1',\n",
    "                 'final/peak_histogram_l2_1', \n",
    "                 'final/psd_l2log_1', \n",
    "                 'cosmology/global_score_1',\n",
    "                 'cosmology/mass_histogram_l2log_1',\n",
    "                 'cosmology/peak_histogram_l2log_1',\n",
    "                 'cosmology/psd_l2log_1',\n",
    "                 'nomap/mass_histogram_log_l2log_1',\n",
    "                 'nomap/peak_histogram_log_l2log_1']\n",
    "measures_list = np.array(measures_list)[selec]\n",
    "\n",
    "names = ['Sum differences',\n",
    "         'Mass histogram',\n",
    "         'Peak histogram',\n",
    "         'Power spectral density',\n",
    "         'Sum difference mapped',\n",
    "         'Mass histogram - Raw',\n",
    "         'Peak histogram - Raw',\n",
    "         'Power spectral density - Raw',\n",
    "         'Mass histogram log - mapped',\n",
    "         'Peak histogram log - mapped']\n",
    "names= np.array(names)[selec]\n",
    "\n",
    "# Getting data\n",
    "duality_gap, it = get_event_data(event_files, 'duality/gap_1', selec_it) \n",
    "duality_minmax, itt = get_event_data(event_files, 'duality/minmax_1', selec_it) \n",
    "np.testing.assert_almost_equal(it,itt)\n",
    "duality_maxmin, itt = get_event_data(event_files, 'duality/maxmin_1', selec_it) \n",
    "np.testing.assert_almost_equal(it,itt)\n",
    "\n",
    "corr_dg = []\n",
    "corr_minmax = []\n",
    "corr_maxmin = []\n",
    "\n",
    "\n",
    "for measures in measures_list:\n",
    "    values, itt = get_event_data(event_files, measures, selec_it) \n",
    "    np.testing.assert_almost_equal(it,itt)\n",
    "    corr_dg.append(np.corrcoef( values, duality_gap))\n",
    "    corr_minmax.append(np.corrcoef(values, duality_minmax))\n",
    "    corr_maxmin.append(np.corrcoef(values, duality_maxmin))\n",
    "\n",
    "corr_dg = np.array(corr_dg)[:,0,1]\n",
    "corr_minmax = np.array(corr_minmax)[:,0,1]\n",
    "corr_maxmin = np.array(corr_maxmin)[:,0,1]\n",
    "plt.plot(corr_dg,'xb', label='Duality gap value')\n",
    "plt.plot(corr_minmax,'xr', label='Minmax value')\n",
    "plt.ylim([0,1])\n",
    "# plt.plot(corr_maxmin,'xg', label='correlation maxmin')\n",
    "plt.legend()\n",
    "plt.title('Correlation measurements')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "========\n",
    "Barchart\n",
    "========\n",
    "\n",
    "A bar plot with errorbars and height labels on individual bars\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = len(corr_dg)\n",
    "\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.35       # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "rects1 = ax.barh(ind, corr_dg, width, color='r')\n",
    "\n",
    "rects2 = ax.barh(ind + width, corr_minmax, width, color='y')\n",
    "# add some text for labels, title and axes ticks\n",
    "# ax.set_xlabel('Score')\n",
    "# ax.set_title('Pearson correlation')\n",
    "ax.set_xlabel('Pearson correlation')\n",
    "\n",
    "ax.set_yticks(ind + width / 2)\n",
    "ax.set_yticklabels(names)\n",
    "ax.set_xlim(0,1)\n",
    "ax.legend((rects1[0], rects2[0]), ('Duality gap value', 'Minimax value'), loc=3, framealpha=1)\n",
    "\n",
    "# for i, v in enumerate(y):\n",
    "#     ax.text(v + 3, i + .25, str(v), color='blue', fontweight='bold')\n",
    "    \n",
    "def autolabel(rects):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar displaying its height\n",
    "    \"\"\"\n",
    "    for rect in rects:\n",
    "        width = rect.get_width()\n",
    "        ax.text(1.08*width,rect.get_y()+rect.get_height(),\n",
    "                '{}'.format((int(100*width)/100)),\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "# plt.show()\n",
    "plt.savefig(pathfig+\"correlation.pdf\", bbox_inches='tight', format='pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N = 150\n",
    "fontsize=12\n",
    "num = 0\n",
    "for measures, name in zip(measures_list[:3], names[:3]):\n",
    "    values, itt = get_event_data(event_files, measures, selec_it)\n",
    "    np.testing.assert_almost_equal(it,itt)\n",
    "    plt.figure(figsize=(10,2))\n",
    "    plt.plot(it[:N], values[:N]/np.max(values), label='Score')\n",
    "    plt.plot(it[:N], duality_gap[:N]/np.max(duality_gap), label='Duality Gap')\n",
    "    plt.title(name)\n",
    "    plt.legend(loc=1, framealpha=1, fontsize=fontsize-2)\n",
    "    plt.xlabel('Iterations', fontsize=fontsize )\n",
    "    plt.ylabel('Normalized metric', fontsize=fontsize)\n",
    "    plt.savefig(pathfig+\"stat\"+str(num)+\".pdf\", bbox_inches='tight', format='pdf')\n",
    "    num = num+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duality_gap, it = get_event_data(event_files, 'duality/gap_1')\n",
    "plt.plot(duality_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_imgs_paper(imgs, nx=2, ny=2,**kwargs):\n",
    "    if len(imgs)<nx*ny:\n",
    "        raise ValueError(\"Not enough samples.\")\n",
    "    fig, ax = plt.subplots(nx, ny, sharey=True, figsize=(11/2*nx,10.5/2*ny))\n",
    "    sn = 0\n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            if nx==1 and ny==1:\n",
    "                tax = ax\n",
    "            elif nx==1:\n",
    "                tax = ax[j]\n",
    "            elif ny==1:\n",
    "                tax = ax[i]\n",
    "            else:\n",
    "                tax = ax[i,j]\n",
    "            tax.imshow(imgs[sn], interpolation='none', **kwargs)\n",
    "            tax.axis('off')\n",
    "            sn += 1\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "real_sample = dataset.get_samples(N=16)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "cmap = plt.cm.plasma\n",
    "clim = (0, np.max(real_sample))\n",
    "fig = plot_imgs_paper(gen_sample,nx=4,ny=4, cmap=cmap, clim=clim);\n",
    "fig.suptitle('Fake samples $32x32$', y=1.03, fontsize=48 )\n",
    "plt.savefig(pathfig+\"fakecosmo.pdf\", bbox_inches='tight', format='pdf')\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "fig = plot_imgs_paper(real_sample,nx=4,ny=4,cmap=cmap, clim=clim);\n",
    "fig.suptitle('Real samples $32x32$', y=1.03, fontsize=48 )\n",
    "plt.savefig(pathfig+\"realcosmo.pdf\", bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
