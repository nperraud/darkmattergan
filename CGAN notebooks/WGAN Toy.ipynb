{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from gantools import data\n",
    "from gantools import utils\n",
    "from gantools import plot\n",
    "from gantools.model import CosmoWGAN\n",
    "from gantools.gansystem import GANsystem\n",
    "from gantools import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: some of the parameters don't make sense for the fake dataset\n",
    "ns = 32 # Resolution of the image\n",
    "try_resume = True # Try to resume previous simulation\n",
    "\n",
    "def non_lin(x):\n",
    "    return tf.nn.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fake images\n",
    "nsamples = 5000\n",
    "sigma = 0.005\n",
    "N = 10\n",
    "image_shape = [ns, ns]\n",
    "images = data.toy_dataset_generator.generate_fake_images(nsamples=nsamples, sigma=sigma, N=N, image_shape=image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to gantools dataset\n",
    "dataset = data.Dataset.Dataset(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset can return an iterator.\n",
    "it = dataset.iter(10)\n",
    "print(next(it).shape)\n",
    "del it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the data\n",
    "X = dataset.get_all_data().flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the histogram of the pixel densities after the forward map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X, 100)\n",
    "print('min: {}'.format(np.min(X)))\n",
    "print('max: {}'.format(np.max(X)))\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to free some memory\n",
    "del X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot 16 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=4, ncols=4, figsize=(15,15))\n",
    "idx = 0\n",
    "imgs = dataset.get_samples(N=16)\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        col.imshow(imgs[idx], vmin=0, vmax=1)\n",
    "        col.axis('off')\n",
    "        idx = idx + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters for the WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_str = '2D_mac'\n",
    "global_path = 'saved_results/Fake Dataset/'\n",
    "\n",
    "name = 'Simple_WGAN_fake_' + str(ns) + '_' + time_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = False\n",
    "\n",
    "# Parameters for the generator\n",
    "params_generator = dict()\n",
    "params_generator['latent_dim'] = 128\n",
    "params_generator['stride'] = [1, 2, 1]\n",
    "params_generator['nfilter'] = [16, 32, 1]\n",
    "params_generator['shape'] = [[5, 5], [5, 5], [5, 5]]\n",
    "params_generator['batch_norm'] = [bn, bn]\n",
    "params_generator['full'] = [16 * 16 * 8]\n",
    "params_generator['summary'] = True\n",
    "params_generator['non_lin'] = non_lin\n",
    "params_generator['in_conv_shape'] = [16, 16]\n",
    "\n",
    "# Parameters for the discriminator\n",
    "params_discriminator = dict()\n",
    "params_discriminator['stride'] = [1, 2, 1]\n",
    "params_discriminator['nfilter'] = [32, 16, 8]\n",
    "params_discriminator['shape'] = [[5, 5], [5, 5], [5, 5]]\n",
    "params_discriminator['batch_norm'] = [bn, bn, bn]\n",
    "params_discriminator['full'] = []\n",
    "params_discriminator['minibatch_reg'] = False\n",
    "params_discriminator['summary'] = True\n",
    "\n",
    "# Optimization parameters\n",
    "d_opt = dict()\n",
    "d_opt['optimizer'] = \"rmsprop\"\n",
    "d_opt['learning_rate'] = 3e-5\n",
    "params_optimization = dict()\n",
    "params_optimization['discriminator'] = deepcopy(d_opt)\n",
    "params_optimization['generator'] = deepcopy(d_opt)\n",
    "params_optimization['n_critic'] = 5\n",
    "params_optimization['batch_size'] = 32\n",
    "params_optimization['epoch'] = 75\n",
    "\n",
    "# Cosmology parameters\n",
    "params_cosmology = dict()\n",
    "params_cosmology['forward_map'] = None\n",
    "params_cosmology['backward_map'] = None\n",
    "\n",
    "# all parameters\n",
    "params = dict()\n",
    "params['net'] = dict() # All the parameters for the model\n",
    "params['net']['generator'] = params_generator\n",
    "params['net']['discriminator'] = params_discriminator\n",
    "params['net']['cosmology'] = params_cosmology # Parameters for the cosmological summaries\n",
    "params['net']['shape'] = [ns, ns, 1] # Shape of the image\n",
    "params['net']['gamma_gp'] = 10 # Gradient penalty\n",
    "\n",
    "params['optimization'] = params_optimization\n",
    "params['summary_every'] = 1000 # Tensorboard summaries every ** iterations\n",
    "params['print_every'] = 500 # Console summaries every ** iterations\n",
    "params['save_every'] = 10000 # Save the model every ** iterations\n",
    "params['summary_dir'] = os.path.join(global_path, name +'_summary/')\n",
    "params['save_dir'] = os.path.join(global_path, name + '_checkpoints/')\n",
    "params['Nstats'] = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume, params = utils.test_resume(try_resume, params)\n",
    "# If a model is reloaded and some parameters have to be changed, then it should be done here.\n",
    "# For example, setting the number of epoch to 5 would be:\n",
    "params['optimization']['epoch'] = 25\n",
    "params['summary_dir'] = os.path.join(global_path, name +'_summary/')\n",
    "params['save_dir'] = os.path.join(global_path, name + '_checkpoints/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wgan = GANsystem(CosmoWGAN, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wgan.train(dataset, resume=resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the sample quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2000 # Number of samples\n",
    "gen_sample = np.squeeze(wgan.generate(N=N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before computing the statistics, we need to invert the mapping\n",
    "raw_images = dataset.get_samples(N)\n",
    "gen_sample_raw = gen_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a few fake samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=4, ncols=4, figsize=(15,15))\n",
    "idx = 0\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        col.imshow(gen_sample_raw[idx], vmin=0, vmax=1)\n",
    "        col.axis('off')\n",
    "        idx = idx + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display real and fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=4, figsize=(20,10))\n",
    "idx = 0\n",
    "real_imgs = dataset.get_samples(4)\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        col.imshow(gen_sample_raw[idx] if idx < 4 else real_imgs[idx % 4], vmin=0, vmax=1)\n",
    "        col.axis('off')\n",
    "        idx = idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenstools = True\n",
    "bin_k = 15\n",
    "box_l = (5*np.pi/180)\n",
    "cut = [50, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logel2, l2, logel1, l1, fd = evaluation.compute_and_plot_psd(raw_images, gen_sample_raw, multiply=True, confidence='std', fractional_difference=True, bin_k=bin_k, box_l=box_l, cut=cut, lenstools=lenstools, loc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logel2, l2, logel1, l1, _ = evaluation.compute_and_plot_peak_count(raw_images, gen_sample_raw, log=False, neighborhood_size=2, threshold=0.01, confidence='std', fractional_difference=True, loc=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logel2, l2, logel1, l1, _ = evaluation.compute_and_plot_mass_hist(raw_images, gen_sample_raw, log=False, confidence='std', lim=(0,1), fractional_difference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lenstools:\n",
    "    ylims = [[(1e-5, 1e-1), (0, 0.1)], [(1e-2, 3e2), (0, 0.35)], [(1e-1, 1e3), (0, 0.25)]]\n",
    "else:\n",
    "    ylims = [[(1e-3, 1e1), (0, 0.1)], [(1e-2, 3e2), (0, 0.35)], [(1e-1, 1e3), (0, 0.25)]]\n",
    "locs = [1, 1, 1]\n",
    "fractional_difference=[True, True, True]\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "_ = evaluation.plot_stats(ax, gen_sample_raw, raw_images, log=False, lim=(0,1), neighborhood_size=2, threshold=0.01, confidence='std', multiply=True, bin_k=bin_k, box_l=box_l, cut=cut, lenstools=lenstools, fractional_difference=fractional_difference, locs=locs, ylims=ylims)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_r, corr_f, k = evaluation.compute_plot_correlation(raw_images, gen_sample_raw, bin_k=bin_k, box_l=box_l, cut=cut, lenstools=lenstools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correlation l2 loss:\", np.linalg.norm(corr_r - corr_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MS-SSIM score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_fake, s_real = evaluation.compute_ssim_score([gen_sample_raw], [raw_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s_fake[0], s_real[0])\n",
    "print(np.abs(s_fake[0] - s_real[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
