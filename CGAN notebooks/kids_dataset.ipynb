{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from gantools.data.load import load_params_dataset\n",
    "from gantools.data import transformation\n",
    "from gantools import utils\n",
    "from gantools import plot\n",
    "from gantools.metric import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset from individual file. The big h5 file has two datasets, called \"train_maps\" and \"train_labels\", containing the maps and corresponding parameters respectively. Moreover, cosmologies have to be grouped. E.g.:\n",
    "\n",
    "map1 param1\n",
    "\n",
    "map2 param1\n",
    "\n",
    "...\n",
    "\n",
    "map100 param1\n",
    "\n",
    "map101 param2\n",
    "\n",
    "map102 param2\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/store/sdsc/sd01/cosmology/KiDs450_maps/maps/\"\n",
    "fileout = \"/scratch/snx3000/smarcon/preprocessed_data/kids.h5\" # TODO: adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(filename):\n",
    "    words = filename.split('_')\n",
    "    return [float(words[3]), float(words[4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(path)\n",
    "files.sort()\n",
    "first = True\n",
    "for file in files:\n",
    "    maps = np.load(path + file) # Load maps\n",
    "    params = get_params(file) # Parse parameters\n",
    "    params = np.tile(np.array(params), [len(maps), 1])\n",
    "    utils.append_h5(fileout, maps, params=params, overwrite=first)\n",
    "    first = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_params_dataset('kids.h5', batch=12000, sorted=True, shape=[128, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_params = dataset.get_different_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diff_params.shape)\n",
    "print(diff_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.scatter(diff_params[:,0], diff_params[:,1])\n",
    "pl.xlabel('$\\Omega_M$', fontsize=14)\n",
    "pl.ylabel('$\\sigma_8$', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = utils.find_minmax(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histo, x = utils.produce_histogram(dataset, lim=(vmin, vmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot.plot_histogram(x, histo)\n",
    "print('min: {}'.format(vmin))\n",
    "print('max: {}'.format(vmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmax = 0.125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pl.subplots(nrows=4, ncols=4, figsize=(15,15))\n",
    "idx = 0\n",
    "imgs = dataset.get_samples(N=16)[0]\n",
    "params = dataset.get_samples(N=16)[1]\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        plot.plot_img(imgs[idx], vmin=vmin, vmax=vmax, ax=col, title=params[idx])\n",
    "        idx = idx + 1\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothing(x):\n",
    "    return transformation.smooth(x, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_params_dataset('kids.h5', batch=12000, sorted=True, shape=[128, 128], transform=smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = utils.find_minmax(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histo, x = utils.produce_histogram(dataset, lim=(vmin, vmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot.plot_histogram(x, histo)\n",
    "print('min: {}'.format(vmin))\n",
    "print('max: {}'.format(vmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmax = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pl.subplots(nrows=4, ncols=4, figsize=(15,15))\n",
    "idx = 0\n",
    "imgs = dataset.get_samples(N=16)[0]\n",
    "params = dataset.get_samples(N=16)[1]\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        plot.plot_img(imgs[idx], vmin=vmin, vmax=vmax, ax=col, title=params[idx])\n",
    "        idx = idx + 1\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd, k = stats.power_spectrum_batch_phys(dataset.get_samples(2000)[0], bin_k=50, box_l=(5*np.pi)/180, log_sampling=False, multiply=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_single(k, psd, confidence='std', shade=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide into test and training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = [[0.137, 1.23],\n",
    "               [0.196, 1.225], # extr\n",
    "               [0.127, 0.836], # extr\n",
    "               [0.25, 0.658],\n",
    "               [0.311, 0.842],\n",
    "               [0.199, 0.87],\n",
    "               [0.254, 0.852],\n",
    "               [0.312, 0.664],\n",
    "               [0.356, 0.614],\n",
    "               [0.421, 0.628],\n",
    "               [0.487, 0.643]] # extr\n",
    "test_params = np.array(test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_map = dict()\n",
    "for i in range(len(diff_params)):\n",
    "    params_map[str(diff_params[i])] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dic = dict()\n",
    "for p in test_params:\n",
    "    if str(p) in params_map.keys():\n",
    "        test_dic[params_map[str(p)]] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_test_params = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dic = dict()\n",
    "for i in range(nr_test_params):\n",
    "    idx = np.random.randint(0, len(diff_params))\n",
    "    while idx in test_dic.keys():\n",
    "        idx = np.random.randint(0, len(diff_params))\n",
    "    test_dic[idx] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two sets and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = []\n",
    "train_params = []\n",
    "for i in range(len(diff_params)):\n",
    "    if i in test_dic.keys():\n",
    "        test_params.append(diff_params[i])\n",
    "    else:\n",
    "        train_params.append(diff_params[i])\n",
    "test_params = np.array(test_params)\n",
    "train_params = np.array(train_params)\n",
    "print(test_params.shape)\n",
    "print(train_params.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.scatter(train_params[:,0], train_params[:,1])\n",
    "pl.scatter(test_params[:, 0], test_params[:, 1], color='r')\n",
    "pl.xlabel('$\\Omega_M$', fontsize=14)\n",
    "pl.ylabel('$\\sigma_8$', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/scratch/snx3000/smarcon/preprocessed_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(path + 'train_test_params_kids.h5', 'w') as f:\n",
    "    f.create_dataset('train', data=train_params)\n",
    "    f.create_dataset('test', data=test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = True\n",
    "for p in test_params:\n",
    "    X, par = dataset.get_data_for_params(p)\n",
    "    utils.append_h5(path + 'kids_test_smooth.h5', X, par, overwrite=first)\n",
    "    first = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = True\n",
    "for p in train_params:\n",
    "    X, par = dataset.get_data_for_params(p)\n",
    "    utils.append_h5(path + 'kids_train_smooth.h5', X, par, overwrite=first)\n",
    "    first = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle training set. Note: this requires a lot of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.shuffle_h5(path + 'kids_train.h5', path + 'kids_train_shuffled.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_params_dataset('kids_train_shuffled.h5', batch=12000, shape=[128, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12000\n",
    "test_prob = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '/scratch/snx3000/smarcon/preprocessed_data/kids_reg_train.h5'\n",
    "test_file = '/scratch/snx3000/smarcon/preprocessed_data/kids_reg_test.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = True\n",
    "X_test = []\n",
    "p_test = []\n",
    "X_train = []\n",
    "p_train = []\n",
    "idx = 0\n",
    "for b in dataset:\n",
    "    if np.random.rand() < test_prob:\n",
    "        X_test.append(b[0, 0])\n",
    "        p_test.append(b[0, 1])\n",
    "    else:\n",
    "        X_train.append(b[0, 0])\n",
    "        p_train.append(b[0, 1])\n",
    "    idx = idx + 1\n",
    "    if idx % batch_size == 0:\n",
    "        utils.append_h5(test_file, np.array(X_test), np.array(p_test), overwrite=first)\n",
    "        utils.append_h5(train_file, np.array(X_train), np.array(p_train), overwrite=first)\n",
    "        first = False\n",
    "        X_test = []\n",
    "        p_test = []\n",
    "        X_train = []\n",
    "        p_train = []\n",
    "if len(X_test) > 0:\n",
    "    utils.append_h5(test_file, np.array(X_test), np.array(p_test), overwrite=first)\n",
    "if len(X_train) > 0:\n",
    "    utils.append_h5(train_file, np.array(X_train), np.array(p_train), overwrite=first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
