{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from moviepy.editor import VideoClip\n",
    "from moviepy.video.io.bindings import mplfig_to_npimage\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from gantools import utils\n",
    "from gantools import plot\n",
    "from gantools.gansystem import GANsystem\n",
    "from gantools.data import Dataset, Dataset_parameters\n",
    "\n",
    "from cosmotools.model import CosmoWGAN\n",
    "from cosmotools.metric import evaluation\n",
    "from cosmotools.data import toy_dataset_generator\n",
    "\n",
    "from gantools.model import ConditionalParamWGAN\n",
    "from gantools.gansystem import GANsystem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = 32 # Resolution of the image\n",
    "try_resume = True # Try to resume previous simulation\n",
    "\n",
    "def non_lin(x):\n",
    "    return tf.nn.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 5000\n",
    "sigma_int = [0.001, 0.01]\n",
    "N_int = [10, 11]\n",
    "image_shape = [ns, ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate toy images\n",
    "images, parameters = toy_dataset_generator.generate_fake_dataset(nsamples=nsamples, sigma_int=sigma_int, N_int=N_int, image_shape=image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images.shape, parameters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to gantools dataset\n",
    "dataset = Dataset_parameters(images, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset can return an iterator.\n",
    "it = dataset.iter(10)\n",
    "current = next(it)\n",
    "print(current[0, 0].shape, current[0, 1].shape)\n",
    "del it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the data\n",
    "X, params = dataset.get_all_data()\n",
    "X = X.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the histogram of the pixel densities after the forward map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X, 100)\n",
    "print('min: {}'.format(np.min(X)))\n",
    "print('max: {}'.format(np.max(X)))\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to free some memory\n",
    "del X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot 16 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, params = dataset.get_samples(N=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=4, ncols=4, figsize=(15,15))\n",
    "idx = 0\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        col.imshow(imgs[idx], vmin=0, vmax=1)\n",
    "        col.set_title(\"sigma: \" + str(params[idx, 0])[0:7] + \", N: \" + str(int(params[idx, 1]) + 1), fontsize=14)\n",
    "        col.axis('off')\n",
    "        idx = idx + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters for the WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_str = '2D_mac'\n",
    "global_path = '../saved_results/Fake_Dataset/'\n",
    "\n",
    "name = 'Simple_WGAN_conditional_' + str(ns) + '_' + time_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = False\n",
    "\n",
    "# Parameters for the generator\n",
    "params_generator = dict()\n",
    "params_generator['latent_dim'] = 128\n",
    "params_generator['stride'] = [2, 2, 1]\n",
    "params_generator['nfilter'] = [16, 32, 1]\n",
    "params_generator['shape'] = [[5, 5], [5, 5], [5, 5]]\n",
    "params_generator['batch_norm'] = [bn, bn]\n",
    "params_generator['full'] = [256, 512, 16 * 16 * 8]\n",
    "params_generator['summary'] = True\n",
    "params_generator['non_lin'] = non_lin\n",
    "params_generator['in_conv_shape'] = [8, 8]\n",
    "\n",
    "# Parameters for the discriminator\n",
    "params_discriminator = dict()\n",
    "params_discriminator['stride'] = [1, 2, 1]\n",
    "params_discriminator['nfilter'] = [32, 16, 8]\n",
    "params_discriminator['shape'] = [[5, 5], [5, 5], [5, 5]]\n",
    "params_discriminator['batch_norm'] = [bn, bn, bn]\n",
    "params_discriminator['full'] = [512, 256, 128]\n",
    "params_discriminator['minibatch_reg'] = False\n",
    "params_discriminator['summary'] = True\n",
    "\n",
    "# Optimization parameters\n",
    "d_opt = dict()\n",
    "d_opt['optimizer'] = \"rmsprop\"\n",
    "d_opt['learning_rate'] = 3e-5\n",
    "params_optimization = dict()\n",
    "params_optimization['discriminator'] = deepcopy(d_opt)\n",
    "params_optimization['generator'] = deepcopy(d_opt)\n",
    "params_optimization['n_critic'] = 5\n",
    "params_optimization['batch_size'] = 32\n",
    "params_optimization['epoch'] = 100\n",
    "\n",
    "# all parameters\n",
    "params = dict()\n",
    "params['net'] = dict() # All the parameters for the model\n",
    "params['net']['generator'] = params_generator\n",
    "params['net']['discriminator'] = params_discriminator\n",
    "params['net']['shape'] = [ns, ns, 1] # Shape of the image\n",
    "params['net']['gamma_gp'] = 10 # Gradient penalty\n",
    "\n",
    "# Conditional params\n",
    "params['net']['prior_normalization'] = False\n",
    "params['net']['cond_params'] = 1\n",
    "params['net']['init_range'] = [sigma_int, N_int]\n",
    "params['net']['prior_distribution'] = \"gaussian_length\"\n",
    "params['net']['final_range'] = [0.1*np.sqrt(params_generator['latent_dim']), 1*np.sqrt(params_generator['latent_dim'])]\n",
    "\n",
    "params['optimization'] = params_optimization\n",
    "params['summary_every'] = 50 # Tensorboard summaries every ** iterations\n",
    "params['print_every'] = 50 # Console summaries every ** iterations\n",
    "params['save_every'] = 10000 # Save the model every ** iterations\n",
    "params['summary_dir'] = os.path.join(global_path, name +'_summary/')\n",
    "params['save_dir'] = os.path.join(global_path, name + '_checkpoints/')\n",
    "params['Nstats'] = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume, params = utils.test_resume(try_resume, params)\n",
    "# If a model is reloaded and some parameters have to be changed, then it should be done here.\n",
    "# For example, setting the number of epoch to 5 would be:\n",
    "# params['optimization']['epoch'] = 5\n",
    "params['summary_dir'] = os.path.join(global_path, name +'_summary/')\n",
    "params['save_dir'] = os.path.join(global_path, name + '_checkpoints/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosmoConditionalParamWGAN(ConditionalParamWGAN, CosmoWGAN):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan = GANsystem(CosmoConditionalParamWGAN, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wgan.train(dataset, resume=resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate new samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_params = np.atleast_2d(np.linspace(0.002, sigma_int[1], 4)).T\n",
    "gen_params = np.concatenate((gen_params, np.ones((4, 1)) * N_int[0]), axis=1)\n",
    "latent = wgan.net.sample_latent(bs=4, params=gen_params)\n",
    "gen_images = wgan.generate(N=4, **{'z': latent}, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=4, figsize=(15, 7.5))\n",
    "idx = 0\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        if idx < 4:\n",
    "            col.imshow(gen_images[idx, :, :, 0], vmin=0, vmax=1)\n",
    "        else:\n",
    "            img = toy_dataset_generator.generate_fake_images(1, sigma=gen_params[idx%4][0], N=int(gen_params[idx%4][1]), image_shape=image_shape)\n",
    "            col.imshow(img[0], vmin=0, vmax=1)\n",
    "        col.set_title(\"$\\sigma$=\" + str(gen_params[idx%4][0])[0:7] + \", $N$=\" + str(int(gen_params[idx%4][1] + 1)), fontsize=14)\n",
    "        col.axis('off')\n",
    "        idx = idx + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = wgan.net.sample_latent(params=np.array([[0.002, 10]]))\n",
    "gen_sample = wgan.generate(N=1, **{'z': latent}, checkpoint=checkpoint)\n",
    "plt.imshow(gen_sample[0, :, :, 0], vmin=0, vmax=1)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Category\" Morphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a latent vector\n",
    "latent_0 = wgan.net.sample_latent(bs=4, params=np.array([[0.001, 10]]))\n",
    "\n",
    "# Draw an unnormalised distribution\n",
    "z = utils.sample_latent(1, wgan.net.params['generator']['latent_dim'], prior=\"gaussian\")\n",
    "\n",
    "# Normalise the distribution to the final range\n",
    "# gen_params = np.linspace(wgan.net.params['final_range'][0], wgan.net.params['final_range'][1], 4)\n",
    "gen_params = np.linspace(0.002, wgan.net.params['init_range'][0][1], 4)\n",
    "for i in range(4):\n",
    "    scaled_p = utils.scale2range(gen_params[i], wgan.net.params['init_range'][0], wgan.net.params['final_range'])\n",
    "    z_r = (z.T * np.sqrt((scaled_p * scaled_p) / np.sum(z * z, axis=1))).T\n",
    "    latent_0[i, :] = z_r[0, :]\n",
    "\n",
    "# Generate images\n",
    "imgs = wgan.generate(N=4, **{'z': latent_0}, checkpoint=checkpoint)[:, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(15,15))\n",
    "idx = 0\n",
    "for col in ax:\n",
    "    col.imshow(imgs[idx], vmin=0, vmax=1)\n",
    "    col.set_title(\"$\\sigma=$\" + str(gen_params[idx])[0:7] + \", $N=$\" + str(int(N_int[1])), fontsize=14)\n",
    "    col.axis('off')\n",
    "    idx = idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "gen_params = []\n",
    "for p in np.linspace(0.001, 0.01, 20):\n",
    "    gen_params.append([p])\n",
    "gen_params = np.array(gen_params)\n",
    "frames = evaluation.generate_samples_same_seed(wgan, gen_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "def make_frame(t):\n",
    "    t = int(t)\n",
    "    ax.clear()\n",
    "    ax.imshow(frames[t][0, :, :, 0], vmin=0, vmax=1)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(\"$\\sigma=$\" + str(gen_params[t][0])[0:7])\n",
    "    return mplfig_to_npimage(fig)\n",
    "\n",
    "animation = VideoClip(make_frame, duration=len(gen_params))\n",
    "plt.close()\n",
    "animation.ipython_display(fps=20, loop=True, autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the sample quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_params = 4\n",
    "gen_params = np.atleast_2d(np.linspace(0.002, 0.008, diff_params)).T\n",
    "gen_params = np.concatenate((gen_params, np.ones((diff_params, 1)) * N_int[0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images_with_params(params, n):\n",
    "    gen_params = np.ones((n, 1)) * params[0]\n",
    "    gen_params = np.concatenate((gen_params, np.ones((n, 1)) * params[1]), axis=1)\n",
    "    latent = wgan.net.sample_latent(bs=n, params=gen_params)\n",
    "    return wgan.generate(N=n, **{'z': latent}, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = 2000\n",
    "real_images = []\n",
    "fake_images = []\n",
    "for i in range(len(gen_params)):\n",
    "    \n",
    "    # Generate real images\n",
    "    raw_images = toy_dataset_generator.generate_fake_images(nsamples=N, sigma=gen_params[i, 0], N=int(gen_params[i, 1]), image_shape=[ns, ns])\n",
    "    \n",
    "    # Generate fake images\n",
    "    gen_images = generate_images_with_params(gen_params[i], N)\n",
    "    \n",
    "    real_images.append(raw_images)\n",
    "    fake_images.append(gen_images[:, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenstools = True\n",
    "bin_k = 15\n",
    "box_l = (5*np.pi/180)\n",
    "cut = [50, 1000]\n",
    "if lenstools:\n",
    "    ylims = [[(5e-5, 2e0), (0, 0.5)], [(1e-1, 1e2), (0, 0.5)], [(4e-1, 1e3), (0, 0.2)]]\n",
    "else:\n",
    "    ylims = [[(1e-3, 2e2), (0, 0.5)], [(1e-1, 1e2), (0, 0.5)], [(4e-1, 1e3), (0, 0.2)]]\n",
    "fractional_difference = [True, True, True]\n",
    "locs = [2, 1, 1]\n",
    "def param_str(par):\n",
    "    return \"$\\sigma=$\" + str(par[0])[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, score = evaluation.compute_plots_for_params(gen_params, real_images, fake_images, log=False, lim=(0,1), neighborhood_size=2, threshold=0.01, confidence='std', multiply=True, ylims=ylims, param_str=param_str, fractional_difference=fractional_difference, bin_k=bin_k, box_l=box_l, cut=cut, locs=locs, lenstools=lenstools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score has shape n_params, n_stats, losses (log_l2, l2, log_l1, l1)\n",
    "print(\"PSD log-L1 losses:\", score[:, 0, 2])\n",
    "print(\"PSD frac diffs:\", score[:, 0, 4])\n",
    "print(\"Peak log-L1 losses:\", score[:, 1, 2])\n",
    "print(\"Mass log-L1 losses:\", score[:, 2, 2])\n",
    "print(\"PSD log-L1 total:\", np.mean(score[:, 0, 2]), \" +/- \", np.std(score[:, 0, 2]))\n",
    "print(\"Peak log-L1 total:\", np.mean(score[:, 1, 2]), \" +/- \", np.std(score[:, 1, 2]))\n",
    "print(\"Mass log-L1 total:\", np.mean(score[:, 2, 2]), \" +/- \", np.std(score[:, 2, 2]))\n",
    "print(\"PSD frac diff:\", np.mean(score[:, 0, 4]), \" +/- \", np.std(score[:, 0, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heat map\n",
    "\n",
    "To have nice plots set gen_params = np.atleast_2d(np.linspace(0.0001, 0.002, 20)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represent heat-map of accuracy\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.scatter(gen_params[:, 0], gen_params[:, 1] + 1, c=score[:, 0, 4], vmin=0, vmax=1, cmap=plt.cm.RdYlGn_r, edgecolor='k')\n",
    "plt.xlabel('$\\sigma$')\n",
    "plt.ylabel('$N$')\n",
    "plt.xlim([-0.001, 0.021])\n",
    "plt.ylim([10, 12])\n",
    "plt.plot(np.array([0.0009, 0.0009, 0.01, 0.01, 0.0009]), np.array([10.5, 11.5, 11.5, 10.5, 10.5]), c='k')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds =[0.08, 0.13, 0.18, 0.23]\n",
    "fig, ax = plt.subplots(nrows=len(thresholds), ncols=1, figsize=(7, len(thresholds) * 2))\n",
    "for j in range(len(thresholds)):\n",
    "    for i in range(len(gen_params)):\n",
    "        ax[j].scatter(gen_params[i, 0], gen_params[i, 1] + 1, c='g' if score[i, 0, 4] <= thresholds[j] else 'r')\n",
    "    ax[j].set_xlabel('$\\sigma$')\n",
    "    ax[j].set_ylabel('$N$')\n",
    "    ax[j].set_xlim([-0.001, 0.021])\n",
    "    ax[j].set_ylim([10, 12])\n",
    "    ax[j].plot(np.array([0.0009, 0.0009, 0.01, 0.01, 0.0009]), np.array([10.5, 11.5, 11.5, 10.5, 10.5]), c='k')\n",
    "    ax[j].set_title(\"Threshold: \" + str(thresholds[j]))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, k = evaluation.compute_correlations(real_images, fake_images, gen_params, bin_k=bin_k, box_l=box_l, cut=cut, lenstools=lenstools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_c = evaluation.plot_correlations(corr, k, gen_params, param_str=param_str, tick_every=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correlation losses:\", score_c)\n",
    "print(\"Total correlation loss:\", np.mean(score_c), \" +/- \", np.std(score_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MS-SSIM score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = wgan.net.sample_latent(bs=len(parameters), params=parameters)\n",
    "gen_images = wgan.generate(N=len(parameters), **{'z': latent}, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_fake, s_real = evaluation.compute_ssim_score([gen_images], [images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s_fake[0])\n",
    "print(s_real[0])\n",
    "print(np.abs(s_fake[0] - s_real[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_fake, s_real = evaluation.compute_ssim_score(fake_images, real_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s_fake)\n",
    "print(s_real)\n",
    "print(np.mean(s_fake), \" +/- \", np.std(s_fake))\n",
    "print(np.mean(s_real), \" +/- \", np.std(s_real))\n",
    "diff = np.abs(s_fake - s_real)\n",
    "print(np.mean(diff), \" +/- \", np.std(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_params = np.array([[0.005, N_int[0]], [0.01, N_int[0]], [0.02, N_int[0]], [0.03, N_int[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images = []\n",
    "fake_images = []\n",
    "for i in range(len(gen_params)):\n",
    "    \n",
    "    # Generate real images\n",
    "    raw_images = data.toy_dataset_generator.generate_fake_images(nsamples=N, sigma=gen_params[i, 0], N=int(gen_params[i, 1]), image_shape=[ns, ns])\n",
    "    \n",
    "    # Generate fake images\n",
    "    gen_images = generate_images_with_params(gen_params[i], N)\n",
    "    \n",
    "    real_images.append(raw_images)\n",
    "    fake_images.append(gen_images[:, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lenstools:\n",
    "    ylims = [[(1e-4, 5e-1), (0, 1)], [(2e-1, 2e2), (0, 0.5)], [(4e-1, 2e3), (0, 0.5)]]\n",
    "else:\n",
    "    ylims = [[(1e-3, 2e1), (0, 1)], [(1e-1, 60), (0, 0.5)], [(4e-1, 1e3), (0, 0.2)]]\n",
    "fractional_difference = [True, True, True]\n",
    "locs = [1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, score = evaluation.compute_plots_for_params(gen_params, real_images, fake_images, log=False, lim=(0,1), neighborhood_size=2, threshold=0.01, confidence='std', multiply=True, bin_k=bin_k, cut=cut, box_l=box_l, ylims=ylims, param_str=param_str, fractional_difference=fractional_difference, locs=locs, lenstools=lenstools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
